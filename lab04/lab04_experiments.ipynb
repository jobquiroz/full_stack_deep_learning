{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cb50d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jobquiroz/full_stack_deep_learning/lab04'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixing path\n",
    "import os\n",
    "\n",
    "os.getcwd()   # Verify where it is right now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11aa081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution, go to lab directory:\n",
    "os.chdir('/home/jobquiroz/full_stack_deep_learning/lab04/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1d16d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.output_result { max-width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, IFrame\n",
    "\n",
    "full_width = True\n",
    "frame_height = 720  # adjust for your screen\n",
    "\n",
    "if full_width:  # if we want the notebook to take up the whole width\n",
    "    # add styling to the notebook's HTML directly\n",
    "    display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "    display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f85f1f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A dataset of images of handwritten text written on a form underneath a typewritten prompt.\n",
      "\n",
      "    \"The IAM Lines dataset, first published at the ICDAR 1999, contains forms of unconstrained handwritten text,\n",
      "    which were scanned at a resolution of 300dpi and saved as PNG images with 256 gray levels.\"\n",
      "    From http://www.fki.inf.unibe.ch/databases/iam-handwriting-database\n",
      "\n",
      "    Images are identified by their \"form ID\". These IDs are used to separate train, validation and test splits,\n",
      "    as keys for dictonaries returning label and image crop region data, and more.\n",
      "\n",
      "    The data split we will use is\n",
      "    IAM lines Large Writer Independent Text Line Recognition Task (LWITLRT): 9,862 text lines.\n",
      "        The validation set has been merged into the train set.\n",
      "        The train set has 7,101 lines from 326 writers.\n",
      "        The test set has 1,861 lines from 128 writers.\n",
      "        The text lines of all data sets are mutually exclusive, thus each writer has contributed to one set only.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from text_recognizer.data.iam import IAM  # base dataset of images of handwritten text\n",
    "from text_recognizer.data import IAMLines  # processed version split into individual lines\n",
    "from text_recognizer.models import LineCNNTransformer  # simple CNN encoder / Transformer decoder\n",
    "\n",
    "print(IAM.__doc__)\n",
    "\n",
    "# uncomment a line below for details on either class\n",
    "# IAMLines??  \n",
    "# LineCNNTransformer??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b325e96",
   "metadata": {},
   "source": [
    "The cell below will train a model on 10% of the data for two epochs.\n",
    "\n",
    "It takes up to a few minutes to run on commodity hardware, including data download and preprocessing. As it's running, continue reading below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c82c8089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                      | Type               | Params\n",
      "------------------------------------------------------------------\n",
      "0  | model                     | LineCNNTransformer | 4.3 M \n",
      "1  | model.line_cnn            | LineCNN            | 1.6 M \n",
      "2  | model.embedding           | Embedding          | 21.2 K\n",
      "3  | model.fc                  | Linear             | 21.3 K\n",
      "4  | model.pos_encoder         | PositionalEncoding | 0     \n",
      "5  | model.transformer_decoder | TransformerDecoder | 2.6 M \n",
      "6  | train_acc                 | Accuracy           | 0     \n",
      "7  | val_acc                   | Accuracy           | 0     \n",
      "8  | test_acc                  | Accuracy           | 0     \n",
      "9  | val_cer                   | CharacterErrorRate | 0     \n",
      "10 | test_cer                  | CharacterErrorRate | 0     \n",
      "11 | loss_fn                   | CrossEntropyLoss   | 0     \n",
      "------------------------------------------------------------------\n",
      "4.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 M     Total params\n",
      "17.189    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model State Dict Disk Size: 17.23 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b484727030bb40759c1c78e6b7a7a8da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5c3631c3cc4f0c86142d8c9bf91b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best model saved at: /home/jobquiroz/full_stack_deep_learning/lab04/training/logs/lightning_logs/version_1/epoch=0000-validation.loss=3.127-validation.cer=1.893.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "───────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "───────────────────────────────────────────────────────────────────────────────────────\n",
      "        test/cer             2.03977632522583\n",
      "        test/loss           3.2378978729248047\n",
      "───────────────────────────────────────────────────────────────────────────────────────\n",
      "CPU times: user 41.8 s, sys: 7.59 s, total: 49.4 s\n",
      "Wall time: 50.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "\n",
    "\n",
    "gpus = int(torch.cuda.is_available()) \n",
    "\n",
    "%run training/run_experiment.py --model_class LineCNNTransformer --data_class IAMLines \\\n",
    "  --loss transformer --batch_size 32 --gpus {gpus} --max_epochs 2 \\\n",
    "  --limit_train_batches 0.1 --limit_val_batches 0.1 --limit_test_batches 0.1 --log_every_n_steps 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9918d49f",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae0db051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use a sequence of bash commands to get the latest experiment's directory\n",
    "#  by hand, you can just copy and paste it from the terminal\n",
    "\n",
    "list_all_log_files = \"find training/logs/lightning_logs/\"  # find avoids issues ls has with \\n in filenames\n",
    "filter_to_folders = \"grep '_[0-9]*$'\"  # regex match on end of line\n",
    "sort_version_descending = \"sort -Vr\"  # uses \"version\" sorting (-V) and reverses (-r)\n",
    "take_first = \"head -n 1\"  # the first n elements, n=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10cfac71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training/logs/lightning_logs/version_0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_log, = ! {list_all_log_files} | {filter_to_folders} | {sort_version_descending} | {take_first}\n",
    "latest_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78857c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 99M\r\n",
      "-rw-r--r-- 1 jobquiroz jobquiroz  50M Aug 30 01:19 'epoch=0000-validation.loss=3.127-validation.cer=1.893.ckpt'\r\n",
      "-rw-r--r-- 1 jobquiroz jobquiroz  50M Aug 30 01:19 'epoch=0001-validation.loss=3.122-validation.cer=1.893.ckpt'\r\n",
      "-rw-r--r-- 1 jobquiroz jobquiroz 1.3K Aug 30 01:19  events.out.tfevents.1661822350.deep-learning.17708.0\r\n",
      "-rw-r--r-- 1 jobquiroz jobquiroz  176 Aug 30 01:19  events.out.tfevents.1661822395.deep-learning.17708.1\r\n",
      "-rw-r--r-- 1 jobquiroz jobquiroz    3 Aug 30 01:19  hparams.yaml\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh {latest_log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "831b0bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "970ed60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-39d372c6f42d07f3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-39d372c6f42d07f3\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# same command works in terminal, with \"{arguments}\" replaced with values or \"$VARIABLES\"\n",
    "\n",
    "port = 6006  # pick an open port on your machine\n",
    "host = \"0.0.0.0\" # allow connections from the internet\n",
    "                 #   watch out! make sure you turn TensorBoard off\n",
    "\n",
    "%tensorboard --logdir {latest_log} --port {port} --host {host}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1132cffc",
   "metadata": {},
   "source": [
    "All lightning_logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c69aceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-633c314a162498e3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-633c314a162498e3\");\n",
       "          const url = new URL(\"/proxy/6007/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir training/logs/lightning_logs --port {port + 1} --host \"0.0.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2c95b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard.manager\n",
    "\n",
    "# get the process IDs for all tensorboard instances\n",
    "pids = [tb.pid for tb in tensorboard.manager.get_all()]\n",
    "\n",
    "done_with_tensorboard = False\n",
    "\n",
    "if done_with_tensorboard:\n",
    "    # kill processes\n",
    "    for pid in pids:\n",
    "        !kill {pid} 2> /dev/null\n",
    "        \n",
    "    # remove the temporary files that sometimes persist, see https://stackoverflow.com/a/59582163\n",
    "    !rm -rf {tensorboard.manager._get_info_dir()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a29742a",
   "metadata": {},
   "source": [
    "## W & B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "605bce55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use wandb to track machine learning work.\n",
      "\n",
      "The most commonly used functions/objects are:\n",
      "  - wandb.init — initialize a new run at the top of your training script\n",
      "  - wandb.config — track hyperparameters and metadata\n",
      "  - wandb.log — log metrics and media over time within your training loop\n",
      "\n",
      "For guides and examples, see https://docs.wandb.com/guides.\n",
      "\n",
      "For scripts and interactive notebooks, see https://github.com/wandb/examples.\n",
      "\n",
      "For reference documentation, see https://docs.wandb.com/ref/python.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "print(wandb.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b88fcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    if args.wandb:\r\n",
      "        logger = pl.loggers.WandbLogger(log_model=\"all\", save_dir=str(log_dir), job_type=\"train\")\r\n",
      "        logger.watch(model, log_freq=max(100, args.log_every_n_steps))\r\n",
      "        logger.log_hyperparams(vars(args))\r\n",
      "        experiment_dir = logger.experiment.dir\r\n",
      "    callbacks += [cb.ModelSizeLogger(), cb.LearningRateMonitor()]\r\n"
     ]
    }
   ],
   "source": [
    "!grep \"args.wandb\" -A 5 training/run_experiment.py | head -n 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c98ff533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "\n",
    "WandbLogger??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b9a9ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjobquiroz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "745c386b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjobquiroz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>training/logs/wandb/run-20220830_014338-1p4bakfy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jobquiroz/full_stack_deep_learning-lab04/runs/1p4bakfy\" target=\"_blank\">atomic-butterfly-1</a></strong> to <a href=\"https://wandb.ai/jobquiroz/full_stack_deep_learning-lab04\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                      | Type               | Params\n",
      "------------------------------------------------------------------\n",
      "0  | model                     | LineCNNTransformer | 4.3 M \n",
      "1  | model.line_cnn            | LineCNN            | 1.6 M \n",
      "2  | model.embedding           | Embedding          | 21.2 K\n",
      "3  | model.fc                  | Linear             | 21.3 K\n",
      "4  | model.pos_encoder         | PositionalEncoding | 0     \n",
      "5  | model.transformer_decoder | TransformerDecoder | 2.6 M \n",
      "6  | train_acc                 | Accuracy           | 0     \n",
      "7  | val_acc                   | Accuracy           | 0     \n",
      "8  | test_acc                  | Accuracy           | 0     \n",
      "9  | val_cer                   | CharacterErrorRate | 0     \n",
      "10 | test_cer                  | CharacterErrorRate | 0     \n",
      "11 | loss_fn                   | CrossEntropyLoss   | 0     \n",
      "------------------------------------------------------------------\n",
      "4.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 M     Total params\n",
      "17.189    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model State Dict Disk Size: 17.23 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87050e50ef44f23bd13a31627a52f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762e141a55e647b795777dd4a63f06ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best model saved at: /home/jobquiroz/full_stack_deep_learning/lab04/training/logs/lightning_logs/version_2/epoch=0009-validation.loss=2.365-validation.cer=0.849.ckpt\n",
      "Best model also uploaded to W&B \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "───────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "───────────────────────────────────────────────────────────────────────────────────────\n",
      "        test/cer             0.908748209476471\n",
      "        test/loss           2.5084540843963623\n",
      "───────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='526.725 MB of 526.725 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>optimizer/lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>size/mb_disk</td><td>▁</td></tr><tr><td>size/nparams</td><td>▁</td></tr><tr><td>test/cer</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>train/loss</td><td>██▆▆▆▇▇▇▇▆▅▃▂▃▃▂▂▂▂▂▁▁▂▁▁▁▂▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>validation/cer</td><td>███▇▇▇▂▇▇▁</td></tr><tr><td>validation/loss</td><td>███▅▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>optimizer/lr-Adam</td><td>0.001</td></tr><tr><td>size/mb_disk</td><td>17.22701</td></tr><tr><td>size/nparams</td><td>4297331</td></tr><tr><td>test/cer</td><td>0.90875</td></tr><tr><td>test/loss</td><td>2.50845</td></tr><tr><td>train/loss</td><td>2.49651</td></tr><tr><td>trainer/global_step</td><td>290</td></tr><tr><td>validation/cer</td><td>0.84905</td></tr><tr><td>validation/loss</td><td>2.36482</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">atomic-butterfly-1</strong>: <a href=\"https://wandb.ai/jobquiroz/full_stack_deep_learning-lab04/runs/1p4bakfy\" target=\"_blank\">https://wandb.ai/jobquiroz/full_stack_deep_learning-lab04/runs/1p4bakfy</a><br/>Synced 6 W&B file(s), 41 media file(s), 1330 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>training/logs/wandb/run-20220830_014338-1p4bakfy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 41s, sys: 32.4 s, total: 3min 13s\n",
      "Wall time: 3min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%run training/run_experiment.py --model_class LineCNNTransformer --data_class IAMLines \\\n",
    "  --loss transformer --batch_size 32 --gpus {gpus} --max_epochs 10 \\\n",
    "  --log_every_n_steps 10 --wandb --limit_test_batches 0.1 \\\n",
    "  --limit_train_batches 0.1 --limit_val_batches 0.1\n",
    "    \n",
    "last_expt = wandb.run\n",
    "\n",
    "wandb.finish()  # necessary in this style of in-notebook experiment running, not necessary in CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf60d62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/jobquiroz/full_stack_deep_learning-lab04/runs/1p4bakfy?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f8ccf220210>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_expt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82822470",
   "metadata": {},
   "source": [
    "### Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a07cd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://wandb.ai/jobquiroz/full_stack_deep_learning-lab04/runs/1p4bakfy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"720\"\n",
       "            src=\"https://wandb.ai/jobquiroz/full_stack_deep_learning-lab04/runs/1p4bakfy\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f8ccfa54c10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(last_expt.url)\n",
    "IFrame(last_expt.url, width=\"100%\", height=frame_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44373682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://wandb.ai/jobquiroz/full_stack_deep_learning-lab04/artifacts/run_table/run-1p4bakfy-trainpredictions/v0/files/train/predictions.table.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"720\"\n",
       "            src=\"https://wandb.ai/jobquiroz/full_stack_deep_learning-lab04/artifacts/run_table/run-1p4bakfy-trainpredictions/v0/files/train/predictions.table.json\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f8ccc1a8690>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_versions_url = last_expt.url.split(\"runs\")[0] + f\"artifacts/run_table/run-{last_expt.id}-trainpredictions/\"\n",
    "table_data_url = table_versions_url + \"v0/files/train/predictions.table.json\"\n",
    "\n",
    "print(table_data_url)\n",
    "IFrame(src=table_data_url, width=\"100%\", height=frame_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "973be9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.callbacks.imtotext import ImageToTextTableLogger\n",
    "\n",
    "\n",
    "ImageToTextTableLogger??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e8025b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.lit_models.base import BaseImageToTextLitModel\n",
    "\n",
    "BaseImageToTextLitModel.add_on_logged_batches??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfce9b5",
   "metadata": {},
   "source": [
    "I'm not done yet..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f12e31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
