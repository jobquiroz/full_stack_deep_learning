{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c81e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jobquiroz/full_stack_deep_learning/lab04/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixing path\n",
    "import os\n",
    "\n",
    "os.getcwd()   # Verify where it is right now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13d98e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution, go to lab directory:\n",
    "os.chdir('/home/jobquiroz/full_stack_deep_learning/lab04/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "052ab8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.output_result { max-width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, IFrame\n",
    "\n",
    "full_width = True\n",
    "frame_height = 720  # adjust for your screen\n",
    "\n",
    "if full_width:  # if we want the notebook to take up the whole width\n",
    "    # add styling to the notebook's HTML directly\n",
    "    display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "    display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d91f726d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A dataset of images of handwritten text written on a form underneath a typewritten prompt.\n",
      "\n",
      "    \"The IAM Lines dataset, first published at the ICDAR 1999, contains forms of unconstrained handwritten text,\n",
      "    which were scanned at a resolution of 300dpi and saved as PNG images with 256 gray levels.\"\n",
      "    From http://www.fki.inf.unibe.ch/databases/iam-handwriting-database\n",
      "\n",
      "    Images are identified by their \"form ID\". These IDs are used to separate train, validation and test splits,\n",
      "    as keys for dictonaries returning label and image crop region data, and more.\n",
      "\n",
      "    The data split we will use is\n",
      "    IAM lines Large Writer Independent Text Line Recognition Task (LWITLRT): 9,862 text lines.\n",
      "        The validation set has been merged into the train set.\n",
      "        The train set has 7,101 lines from 326 writers.\n",
      "        The test set has 1,861 lines from 128 writers.\n",
      "        The text lines of all data sets are mutually exclusive, thus each writer has contributed to one set only.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from text_recognizer.data.iam import IAM  # base dataset of images of handwritten text\n",
    "from text_recognizer.data import IAMLines  # processed version split into individual lines\n",
    "from text_recognizer.models import LineCNNTransformer  # simple CNN encoder / Transformer decoder\n",
    "\n",
    "print(IAM.__doc__)\n",
    "\n",
    "# uncomment a line below for details on either class\n",
    "# IAMLines??  \n",
    "# LineCNNTransformer??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c0e354",
   "metadata": {},
   "source": [
    "The cell below will train a model on 10% of the data for two epochs.\n",
    "\n",
    "It takes up to a few minutes to run on commodity hardware, including data download and preprocessing. As it's running, continue reading below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c660cc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                      | Type               | Params\n",
      "------------------------------------------------------------------\n",
      "0  | model                     | LineCNNTransformer | 4.3 M \n",
      "1  | model.line_cnn            | LineCNN            | 1.6 M \n",
      "2  | model.embedding           | Embedding          | 21.2 K\n",
      "3  | model.fc                  | Linear             | 21.3 K\n",
      "4  | model.pos_encoder         | PositionalEncoding | 0     \n",
      "5  | model.transformer_decoder | TransformerDecoder | 2.6 M \n",
      "6  | train_acc                 | Accuracy           | 0     \n",
      "7  | val_acc                   | Accuracy           | 0     \n",
      "8  | test_acc                  | Accuracy           | 0     \n",
      "9  | val_cer                   | CharacterErrorRate | 0     \n",
      "10 | test_cer                  | CharacterErrorRate | 0     \n",
      "11 | loss_fn                   | CrossEntropyLoss   | 0     \n",
      "------------------------------------------------------------------\n",
      "4.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 M     Total params\n",
      "17.189    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model State Dict Disk Size: 17.23 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4236db25b8594ee994f9a867773b2879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d22e318afd54e86bb5049305c59b9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best model saved at: /home/jobquiroz/full_stack_deep_learning/lab04/training/logs/lightning_logs/version_5/epoch=0000-validation.loss=3.127-validation.cer=1.893.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "──────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "──────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test/cer             2.03977632522583\n",
      "        test/loss            3.238344192504883\n",
      "──────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "CPU times: user 43.6 s, sys: 8.35 s, total: 52 s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "\n",
    "\n",
    "gpus = int(torch.cuda.is_available()) \n",
    "\n",
    "%run training/run_experiment.py --model_class LineCNNTransformer --data_class IAMLines \\\n",
    "  --loss transformer --batch_size 32 --gpus {gpus} --max_epochs 2 \\\n",
    "  --limit_train_batches 0.1 --limit_val_batches 0.1 --limit_test_batches 0.1 --log_every_n_steps 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9227a1b3",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5fec690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use a sequence of bash commands to get the latest experiment's directory\n",
    "#  by hand, you can just copy and paste it from the terminal\n",
    "\n",
    "list_all_log_files = \"find training/logs/lightning_logs/\"  # find avoids issues ls has with \\n in filenames\n",
    "filter_to_folders = \"grep '_[0-9]*$'\"  # regex match on end of line\n",
    "sort_version_descending = \"sort -Vr\"  # uses \"version\" sorting (-V) and reverses (-r)\n",
    "take_first = \"head -n 1\"  # the first n elements, n=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45b9c821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training/logs/lightning_logs/version_5'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_log, = ! {list_all_log_files} | {filter_to_folders} | {sort_version_descending} | {take_first}\n",
    "latest_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ddc9912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 99M\r\n",
      "-rw-r--r-- 1 jobquiroz jobquiroz  50M Aug 31 17:18 'epoch=0000-validation.loss=3.127-validation.cer=1.893.ckpt'\r\n",
      "-rw-r--r-- 1 jobquiroz jobquiroz  50M Aug 31 17:18 'epoch=0001-validation.loss=3.122-validation.cer=1.893.ckpt'\r\n",
      "-rw-r--r-- 1 jobquiroz jobquiroz 1.3K Aug 31 17:18  events.out.tfevents.1661966286.deep-learning.2945.0\r\n",
      "-rw-r--r-- 1 jobquiroz jobquiroz  176 Aug 31 17:18  events.out.tfevents.1661966332.deep-learning.2945.1\r\n",
      "-rw-r--r-- 1 jobquiroz jobquiroz    3 Aug 31 17:18  hparams.yaml\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh {latest_log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d924f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e80bda5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-39d372c6f42d07f3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-39d372c6f42d07f3\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# same command works in terminal, with \"{arguments}\" replaced with values or \"$VARIABLES\"\n",
    "\n",
    "port = 6006  # pick an open port on your machine\n",
    "host = \"0.0.0.0\" # allow connections from the internet\n",
    "                 #   watch out! make sure you turn TensorBoard off\n",
    "\n",
    "%tensorboard --logdir {latest_log} --port {port} --host {host}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3396f04",
   "metadata": {},
   "source": [
    "All lightning_logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e794b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-633c314a162498e3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-633c314a162498e3\");\n",
       "          const url = new URL(\"/proxy/6007/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir training/logs/lightning_logs --port {port + 1} --host \"0.0.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "feeddaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard.manager\n",
    "\n",
    "# get the process IDs for all tensorboard instances\n",
    "pids = [tb.pid for tb in tensorboard.manager.get_all()]\n",
    "\n",
    "done_with_tensorboard = False\n",
    "\n",
    "if done_with_tensorboard:\n",
    "    # kill processes\n",
    "    for pid in pids:\n",
    "        !kill {pid} 2> /dev/null\n",
    "        \n",
    "    # remove the temporary files that sometimes persist, see https://stackoverflow.com/a/59582163\n",
    "    !rm -rf {tensorboard.manager._get_info_dir()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1534551a",
   "metadata": {},
   "source": [
    "## W & B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a08cc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use wandb to track machine learning work.\n",
      "\n",
      "The most commonly used functions/objects are:\n",
      "  - wandb.init — initialize a new run at the top of your training script\n",
      "  - wandb.config — track hyperparameters and metadata\n",
      "  - wandb.log — log metrics and media over time within your training loop\n",
      "\n",
      "For guides and examples, see https://docs.wandb.com/guides.\n",
      "\n",
      "For scripts and interactive notebooks, see https://github.com/wandb/examples.\n",
      "\n",
      "For reference documentation, see https://docs.wandb.com/ref/python.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "print(wandb.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3b47677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    if args.wandb:\r\n",
      "        logger = pl.loggers.WandbLogger(log_model=\"all\", save_dir=str(log_dir), job_type=\"train\")\r\n",
      "        logger.watch(model, log_freq=max(100, args.log_every_n_steps))\r\n",
      "        logger.log_hyperparams(vars(args))\r\n",
      "        experiment_dir = logger.experiment.dir\r\n",
      "    callbacks += [cb.ModelSizeLogger(), cb.LearningRateMonitor()]\r\n"
     ]
    }
   ],
   "source": [
    "!grep \"args.wandb\" -A 5 training/run_experiment.py | head -n 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c469c485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "\n",
    "WandbLogger??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "059357fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjobquiroz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab57aff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjobquiroz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>training/logs/wandb/run-20220831_171856-1rp5c8fe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jobquiroz/full_stack_deep_learning-lab04/runs/1rp5c8fe\" target=\"_blank\">charmed-frog-3</a></strong> to <a href=\"https://wandb.ai/jobquiroz/full_stack_deep_learning-lab04\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                      | Type               | Params\n",
      "------------------------------------------------------------------\n",
      "0  | model                     | LineCNNTransformer | 4.3 M \n",
      "1  | model.line_cnn            | LineCNN            | 1.6 M \n",
      "2  | model.embedding           | Embedding          | 21.2 K\n",
      "3  | model.fc                  | Linear             | 21.3 K\n",
      "4  | model.pos_encoder         | PositionalEncoding | 0     \n",
      "5  | model.transformer_decoder | TransformerDecoder | 2.6 M \n",
      "6  | train_acc                 | Accuracy           | 0     \n",
      "7  | val_acc                   | Accuracy           | 0     \n",
      "8  | test_acc                  | Accuracy           | 0     \n",
      "9  | val_cer                   | CharacterErrorRate | 0     \n",
      "10 | test_cer                  | CharacterErrorRate | 0     \n",
      "11 | loss_fn                   | CrossEntropyLoss   | 0     \n",
      "------------------------------------------------------------------\n",
      "4.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 M     Total params\n",
      "17.189    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model State Dict Disk Size: 17.23 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9c3add94f44f7ea5cf58e91f27008c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "decd6bcc0366484e9c5170849820217a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best model saved at: /home/jobquiroz/full_stack_deep_learning/lab04/training/logs/lightning_logs/version_6/epoch=0006-validation.loss=2.467-validation.cer=0.863.ckpt\n",
      "Best model also uploaded to W&B \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test/cer            0.9909008145332336\n",
      "        test/loss           2.4565465450286865\n",
      "────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='477.423 MB of 477.423 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>optimizer/lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>size/mb_disk</td><td>▁</td></tr><tr><td>size/nparams</td><td>▁</td></tr><tr><td>test/cer</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>train/loss</td><td>██▇▇▇▇▇▇▆▅▄▃▂▃▃▂▂▃▂▂▂▁▂▁▁▁▂▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>validation/cer</td><td>███▆▇▇▁▁▇▁</td></tr><tr><td>validation/loss</td><td>███▄▃▃▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>optimizer/lr-Adam</td><td>0.001</td></tr><tr><td>size/mb_disk</td><td>17.22701</td></tr><tr><td>size/nparams</td><td>4297331</td></tr><tr><td>test/cer</td><td>0.9909</td></tr><tr><td>test/loss</td><td>2.45655</td></tr><tr><td>train/loss</td><td>2.44501</td></tr><tr><td>trainer/global_step</td><td>290</td></tr><tr><td>validation/cer</td><td>0.91781</td></tr><tr><td>validation/loss</td><td>2.3235</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">charmed-frog-3</strong>: <a href=\"https://wandb.ai/jobquiroz/full_stack_deep_learning-lab04/runs/1rp5c8fe\" target=\"_blank\">https://wandb.ai/jobquiroz/full_stack_deep_learning-lab04/runs/1rp5c8fe</a><br/>Synced 6 W&B file(s), 41 media file(s), 1329 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>training/logs/wandb/run-20220831_171856-1rp5c8fe/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 42s, sys: 28.4 s, total: 3min 11s\n",
      "Wall time: 3min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "%run training/run_experiment.py --model_class LineCNNTransformer --data_class IAMLines \\\n",
    "  --loss transformer --batch_size 32 --gpus {gpus} --max_epochs 10 \\\n",
    "  --log_every_n_steps 10 --wandb --limit_test_batches 0.1 \\\n",
    "  --limit_train_batches 0.1 --limit_val_batches 0.1\n",
    "    \n",
    "last_expt = wandb.run\n",
    "\n",
    "wandb.finish()  # necessary in this style of in-notebook experiment running, not necessary in CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65026319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/jobquiroz/full_stack_deep_learning-lab04/runs/1rp5c8fe?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f89255c2ed0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_expt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a881304",
   "metadata": {},
   "source": [
    "### Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcbf9f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://wandb.ai/jobquiroz/full_stack_deep_learning-lab04/runs/1rp5c8fe\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"720\"\n",
       "            src=\"https://wandb.ai/jobquiroz/full_stack_deep_learning-lab04/runs/1rp5c8fe\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f891eec8910>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(last_expt.url)\n",
    "IFrame(last_expt.url, width=\"100%\", height=frame_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18aef3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://wandb.ai/jobquiroz/full_stack_deep_learning-lab04/artifacts/run_table/run-1rp5c8fe-trainpredictions/v0/files/train/predictions.table.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"720\"\n",
       "            src=\"https://wandb.ai/jobquiroz/full_stack_deep_learning-lab04/artifacts/run_table/run-1rp5c8fe-trainpredictions/v0/files/train/predictions.table.json\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f891eec8b10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_versions_url = last_expt.url.split(\"runs\")[0] + f\"artifacts/run_table/run-{last_expt.id}-trainpredictions/\"\n",
    "table_data_url = table_versions_url + \"v0/files/train/predictions.table.json\"\n",
    "\n",
    "print(table_data_url)\n",
    "IFrame(src=table_data_url, width=\"100%\", height=frame_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed807b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.callbacks.imtotext import ImageToTextTableLogger\n",
    "\n",
    "ImageToTextTableLogger??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfb46779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.lit_models.base import BaseImageToTextLitModel\n",
    "\n",
    "BaseImageToTextLitModel.add_on_logged_batches??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a895607",
   "metadata": {},
   "source": [
    "I'm not done yet..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e83d8c",
   "metadata": {},
   "source": [
    "## Projects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2debe62b",
   "metadata": {},
   "source": [
    "### Programmatic Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f60dd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jobquiroz'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_expt.entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23b245d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'full_stack_deep_learning-lab04'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_expt.project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1c44cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1rp5c8fe'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_expt.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7bb147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fc15ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trainer/global_step</th>\n",
       "      <th>_step</th>\n",
       "      <th>_runtime</th>\n",
       "      <th>size/nparams</th>\n",
       "      <th>size/mb_disk</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>validation/predictions</th>\n",
       "      <th>optimizer/lr-Adam</th>\n",
       "      <th>train/predictions</th>\n",
       "      <th>train/loss</th>\n",
       "      <th>...</th>\n",
       "      <th>gradients/transformer_decoder.layers.0.norm3.bias</th>\n",
       "      <th>gradients/transformer_decoder.layers.2.self_attn.in_proj_weight</th>\n",
       "      <th>gradients/transformer_decoder.layers.1.self_attn.in_proj_weight</th>\n",
       "      <th>gradients/transformer_decoder.layers.0.linear1.weight</th>\n",
       "      <th>gradients/line_cnn.convs.2.conv.weight</th>\n",
       "      <th>gradients/transformer_decoder.layers.1.norm3.weight</th>\n",
       "      <th>gradients/transformer_decoder.layers.1.self_attn.out_proj.weight</th>\n",
       "      <th>gradients/transformer_decoder.layers.1.norm2.weight</th>\n",
       "      <th>test/cer</th>\n",
       "      <th>test/loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4297331.0</td>\n",
       "      <td>17.22701</td>\n",
       "      <td>1661966344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1661966346</td>\n",
       "      <td>{'artifact_path': 'wandb-client-artifact://t9r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1661966347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1661966349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1661966350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'path': 'media/table/train/predictions_4_9748...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trainer/global_step  _step  _runtime  size/nparams  size/mb_disk  \\\n",
       "0                   -1      0         8     4297331.0      17.22701   \n",
       "1                   -1      1        10           NaN           NaN   \n",
       "2                    0      2        11           NaN           NaN   \n",
       "3                    9      3        13           NaN           NaN   \n",
       "4                    9      4        14           NaN           NaN   \n",
       "\n",
       "   _timestamp                             validation/predictions  \\\n",
       "0  1661966344                                                NaN   \n",
       "1  1661966346  {'artifact_path': 'wandb-client-artifact://t9r...   \n",
       "2  1661966347                                                NaN   \n",
       "3  1661966349                                                NaN   \n",
       "4  1661966350                                                NaN   \n",
       "\n",
       "   optimizer/lr-Adam                                  train/predictions  \\\n",
       "0                NaN                                                NaN   \n",
       "1                NaN                                                NaN   \n",
       "2              0.001                                                NaN   \n",
       "3              0.001                                                NaN   \n",
       "4                NaN  {'path': 'media/table/train/predictions_4_9748...   \n",
       "\n",
       "   train/loss  ...  gradients/transformer_decoder.layers.0.norm3.bias  \\\n",
       "0         NaN  ...                                                NaN   \n",
       "1         NaN  ...                                                NaN   \n",
       "2         NaN  ...                                                NaN   \n",
       "3         NaN  ...                                                NaN   \n",
       "4         NaN  ...                                                NaN   \n",
       "\n",
       "   gradients/transformer_decoder.layers.2.self_attn.in_proj_weight  \\\n",
       "0                                                NaN                 \n",
       "1                                                NaN                 \n",
       "2                                                NaN                 \n",
       "3                                                NaN                 \n",
       "4                                                NaN                 \n",
       "\n",
       "   gradients/transformer_decoder.layers.1.self_attn.in_proj_weight  \\\n",
       "0                                                NaN                 \n",
       "1                                                NaN                 \n",
       "2                                                NaN                 \n",
       "3                                                NaN                 \n",
       "4                                                NaN                 \n",
       "\n",
       "  gradients/transformer_decoder.layers.0.linear1.weight  \\\n",
       "0                                                NaN      \n",
       "1                                                NaN      \n",
       "2                                                NaN      \n",
       "3                                                NaN      \n",
       "4                                                NaN      \n",
       "\n",
       "  gradients/line_cnn.convs.2.conv.weight  \\\n",
       "0                                    NaN   \n",
       "1                                    NaN   \n",
       "2                                    NaN   \n",
       "3                                    NaN   \n",
       "4                                    NaN   \n",
       "\n",
       "  gradients/transformer_decoder.layers.1.norm3.weight  \\\n",
       "0                                                NaN    \n",
       "1                                                NaN    \n",
       "2                                                NaN    \n",
       "3                                                NaN    \n",
       "4                                                NaN    \n",
       "\n",
       "  gradients/transformer_decoder.layers.1.self_attn.out_proj.weight  \\\n",
       "0                                                NaN                 \n",
       "1                                                NaN                 \n",
       "2                                                NaN                 \n",
       "3                                                NaN                 \n",
       "4                                                NaN                 \n",
       "\n",
       "  gradients/transformer_decoder.layers.1.norm2.weight test/cer test/loss  \n",
       "0                                                NaN       NaN       NaN  \n",
       "1                                                NaN       NaN       NaN  \n",
       "2                                                NaN       NaN       NaN  \n",
       "3                                                NaN       NaN       NaN  \n",
       "4                                                NaN       NaN       NaN  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = wb_api.run(\"/\".join( # fetch a run given\n",
    "    [last_expt.entity,     # the user or org it was logged to\n",
    "     last_expt.project,    # the \"project\", usually one of several per repo/application\n",
    "     last_expt.id]         # and a unique ID\n",
    "))\n",
    "\n",
    "hist = run.history()  # and pull down a sample of the data as a pandas DataFrame\n",
    "\n",
    "hist.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae3dcaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epoch\n",
       "0.0     3.321208\n",
       "1.0     3.160990\n",
       "2.0     3.174500\n",
       "3.0     2.961284\n",
       "4.0     2.642284\n",
       "5.0     2.658995\n",
       "6.0     2.599283\n",
       "7.0     2.531157\n",
       "8.0     2.486359\n",
       "9.0     2.502108\n",
       "10.0         NaN\n",
       "Name: train/loss, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.groupby(\"epoch\")[\"train/loss\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11bbbf26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact of type run_table: run-1rp5c8fe-validationpredictions:v0\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v0\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v1\n",
      "artifact of type run_table: run-1rp5c8fe-validationpredictions:v1\n",
      "artifact of type model: model-1rp5c8fe:v0\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v2\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v3\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v4\n",
      "artifact of type run_table: run-1rp5c8fe-validationpredictions:v2\n",
      "artifact of type model: model-1rp5c8fe:v1\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v5\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v6\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v7\n",
      "artifact of type run_table: run-1rp5c8fe-validationpredictions:v3\n",
      "artifact of type model: model-1rp5c8fe:v2\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v8\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v9\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v10\n",
      "artifact of type run_table: run-1rp5c8fe-validationpredictions:v4\n",
      "artifact of type model: model-1rp5c8fe:v3\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v11\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v12\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v13\n",
      "artifact of type run_table: run-1rp5c8fe-validationpredictions:v5\n",
      "artifact of type model: model-1rp5c8fe:v4\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v14\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v15\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v16\n",
      "artifact of type run_table: run-1rp5c8fe-validationpredictions:v6\n",
      "artifact of type model: model-1rp5c8fe:v5\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v17\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v18\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v19\n",
      "artifact of type run_table: run-1rp5c8fe-validationpredictions:v7\n",
      "artifact of type model: model-1rp5c8fe:v6\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v20\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v21\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v22\n",
      "artifact of type run_table: run-1rp5c8fe-validationpredictions:v8\n",
      "artifact of type model: model-1rp5c8fe:v7\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v23\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v24\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v25\n",
      "artifact of type run_table: run-1rp5c8fe-validationpredictions:v9\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v26\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v27\n",
      "artifact of type run_table: run-1rp5c8fe-trainpredictions:v28\n",
      "artifact of type run_table: run-1rp5c8fe-validationpredictions:v10\n",
      "artifact of type model: model-1rp5c8fe:v8\n"
     ]
    }
   ],
   "source": [
    "# which artifacts where created and logged?\n",
    "artifacts = run.logged_artifacts()\n",
    "\n",
    "for artifact in artifacts:\n",
    "    print(f\"artifact of type {artifact.type}: {artifact.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69af39a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "artifact = wb_api.artifact(f\"{last_expt.entity}/{last_expt.project}/run-{last_expt.id}-trainpredictions:latest\")\n",
    "artifact_dir = Path(artifact.download(root=\"training/logs\"))\n",
    "image_dir = artifact_dir / \"media\" / \"images\"\n",
    "\n",
    "images = [path for path in image_dir.iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7df44997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('training/logs')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26470313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 24\r\n",
      "drwxr-xr-x 6 jobquiroz jobquiroz 4096 Aug 30 19:35 .\r\n",
      "drwxr-xr-x 4 jobquiroz jobquiroz 4096 Aug 30 01:17 ..\r\n",
      "drwxr-xr-x 9 jobquiroz jobquiroz 4096 Aug 31 17:19 lightning_logs\r\n",
      "drwxr-xr-x 3 jobquiroz jobquiroz 4096 Aug 30 19:35 media\r\n",
      "drwxr-xr-x 2 jobquiroz jobquiroz 4096 Aug 30 19:35 train\r\n",
      "drwxr-xr-x 5 jobquiroz jobquiroz 4096 Aug 31 17:18 wandb\r\n"
     ]
    }
   ],
   "source": [
    "!ls training/logs -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "339b114e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('training/logs/media/images/cf869b842dee0124639b.png'),\n",
       " PosixPath('training/logs/media/images/eb9073928afd080006fa.png'),\n",
       " PosixPath('training/logs/media/images/908cb06b021569d7ea8f.png'),\n",
       " PosixPath('training/logs/media/images/8dad95613bae624d82bb.png'),\n",
       " PosixPath('training/logs/media/images/a860db868e00dd9dab66.png'),\n",
       " PosixPath('training/logs/media/images/7307df1b02786438b4c7.png'),\n",
       " PosixPath('training/logs/media/images/e97392ce19f66089ad50.png'),\n",
       " PosixPath('training/logs/media/images/da9279714d1698cefc6f.png'),\n",
       " PosixPath('training/logs/media/images/cd49cf8327a16fa9e36d.png'),\n",
       " PosixPath('training/logs/media/images/a3deacb3a70e1e6c2e09.png'),\n",
       " PosixPath('training/logs/media/images/ae44cd874a3442bd1a8e.png'),\n",
       " PosixPath('training/logs/media/images/261ab814bbf3201891f7.png'),\n",
       " PosixPath('training/logs/media/images/eb17fe4876fccb9627ff.png'),\n",
       " PosixPath('training/logs/media/images/93ce94f09bd14c7a5b16.png'),\n",
       " PosixPath('training/logs/media/images/a7f3b95017ce8bafe519.png'),\n",
       " PosixPath('training/logs/media/images/9716e646520f5bb320ce.png'),\n",
       " PosixPath('training/logs/media/images/3b483a9a12a649919ca2.png'),\n",
       " PosixPath('training/logs/media/images/3067e6495c79910c64bf.png'),\n",
       " PosixPath('training/logs/media/images/0806931525cb1bc188f9.png'),\n",
       " PosixPath('training/logs/media/images/ab5c61596462a6d918d0.png'),\n",
       " PosixPath('training/logs/media/images/c4e7b66dd42030af2bf9.png'),\n",
       " PosixPath('training/logs/media/images/b3467404dc395d8899ad.png'),\n",
       " PosixPath('training/logs/media/images/378b3ac01424f98fd8ce.png'),\n",
       " PosixPath('training/logs/media/images/5e546b86ed4a88ed77f6.png'),\n",
       " PosixPath('training/logs/media/images/9165749803518277b189.png'),\n",
       " PosixPath('training/logs/media/images/d196dbf73514b4e8cccf.png'),\n",
       " PosixPath('training/logs/media/images/c82c6659d0741111e8f4.png'),\n",
       " PosixPath('training/logs/media/images/9a3a8c1a9603b7854db2.png'),\n",
       " PosixPath('training/logs/media/images/429b538403a4d8f6a9df.png'),\n",
       " PosixPath('training/logs/media/images/cee33ac8de1e0396f07c.png'),\n",
       " PosixPath('training/logs/media/images/e27a3312109152b2dff5.png'),\n",
       " PosixPath('training/logs/media/images/a43a3119e8da207e05cb.png')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ffd604f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABgAAAAA4CAIAAAC0daTGAABU40lEQVR4nO2913cbaX7mXwiFnHMiGABmShSDAtUKHaV2z7htj/vMuO0b+9gX+x/sn7L3e3zO2GvPePa47Z2dVo+ktnKiSIokAJIgCJDIOcfCXjw/1a8aICkmpe73c9FHDQIV3yrgfer5Pl+eUCikjgqfz2cY5sgfJxAIBALhnYLP51MU9Y58tTWbzbe9CQQCgUAgEAiEHw/8drt95A8zDIPfygQCgUAgEE4W8g1LIBAIBAKBQDhBeBRFdZuABAIBn89vt9vk8SOBQCAQCG8L8i1MIBAIBAKBQDgphFSXkYfP54tEIoVCIRKJcrlcpVJptVpvZmtITRmhm3eqIoNAIBDeJORrkUAgEAgEAoFwUuwytYYepFQq3W732NiYRCI5Tk7QPgiFQpFI9PqWT/gxQUohCATCTxA+n8/j8d72VhAIBAKBQCAQfgz8f8pLhwkIlh+9Xm80GimKWllZOXEfEOszkkgktVotn8/XajVsBnnaSeCC8cDn88nYIBAIP0H4fP4b8+ESCAQCgUAgEH7E7C4AVavVTCYTj8dnZ2eNRmMkEmm1WpVK5cRXr9PpHA6HQCBYX18PhUL1ep3M8AndtNvtVqslEAje9oYQCIR3lPdRID5gfSuPx+PxeMfp2EAgEAgEAoFAIFAoAQMdDxir1Woymdza2tJoNBcuXFAoFDRNn+CKeTyeUCikaVqhUCgUCr1er1KpyAyfsCuogHjvZneEtw6fzyd3lZ8I7+P9gWGYA242qYElEAgEAoFAIByf//83Zfsl+N9KpZJMJgOBgFgsnpub02q1IpEIbzuRFcPTIRKJRCKRRqMRiURisfhElkz4UUJSMAiHhc/nC4VCqVSqVqtJ0BjhvQYmoLe9FQQCgUAgEAiE95sfPFTseBSJQrBwOKxQKC5fvnziJiCKong8nkKhaLfbEolEIBCIxWLynJNAOBodGi6BYRiaprVa7eDgoMlkIhoQ4R3k4Jct+XIkEAgEAoFAIByTH/yg7DYBRaPRTCZD0/TExIROpxOJRCf1EJJhmFarlclkDAaD1WrV6/VqtVoikZCHnIT3EWRUv91tEAgENE3TNP0mi57e+l7vD8MwCoVCq9VOTExoNJq3vTmEt8xbUUhP6ubA4/He8cuNQCAQCAQCgfCO0/lrkvvjuN1u5/N5v9+fzWZVKtWFCxdomj7Bp+gwHMViMbPZbDAYlEqlXC4nhWCE9xG2Vdnb2gCBQCCRSMxms9PpNBgMMpnsDchAyPBSq9UikehdkMA64PP57XZbJpOZTCaz2Wy326VS6dveKMLbhH3AQNO0VCqlaRqDBF0ppVLp67CJ7X9z4L3kIIt61y4xAoFAIBAIBML7ReePXa4AxDBMoVDw+/3JZNJgMAwNDVmt1s3NzYPnVu5PvV5vNBrFYlEsFpvNZplMJpVKxWJxrVYjLW8J7wIikUgoFLbb7Xq9/sox+XYzaNvttlgsNhqNw8PDhUJhdXU1Ho9XKhVs9msy1gmFQsgrxWIxGo1Wq9XXsZbjIBQKy+UypJ9UKhUOh19HN0PCewT6D8jlcr1eLxQKE4lEoVBgGEYikWg0GoZhUqlUrVY72cv5BJf2PjY7IxAIBAKBQCC8I+zyOJE70W2328lkcn5+vtFoaLXamZkZPp9/zMkkt9CsUCjU6/VsNqvVao1GI5/PF4vFSJsmEN46Uqm0p6fH7XZbrdZ3f1iKRCK73e50Ovv6+vR6PQpGcLW+prIXPp+vVqt1Op3D4TCZTO9ahhfDMHw+XyaTCYVCq9VqMBgUCsW7fx4JbwCNRuNyua5cuTIzM2OxWCD1WiyWM2fO9PT0SKXS1zqSd134Adf4Tl1iBAKBQCAQCIT3i91/SrIPGBmGKZfLm5uboVBILBb39PT09PQcUwDifrxSqeBxa7vd1ul0KpUKhSSkc/NbhM/no9bvpzzTgEaZy+XMZvP09PTHH39ss9ne5RRhhmEajQZFUSMjI2q1WqlUNptNXMivr38Qamf0er1KpdJoNAKB4F3L8KpWq81mUyAQ6HQ6t9vdaDTIvYWAm1tPT8/o6Oj169dHR0d1Op1AIJBKpW63++OPPzYajSdSjPyaIod+yndmAoFAIBAIBMJxeIUARFFUs9mMxWKPHz+WSqV6vX50dBTOguP/rkUn+Gg0mkgktFqtXC43GAxSqfRdm0P+pEAWhlar7evrMxgMJ9737f2i3W7v7OxoNJpTp059+umnJpPpXZ56we9TKpVsNhv6673uUhEEqQiFQiS4y+Xyd+348Pn8VquFqlWBQOB0OiFave3tIrxNWGccwzCVSkUmk0kkEjx7EIlETqdzYGAAA/uYQwVrwWJlMhmisqiX3rSON3Nf5P6j+53H9+ESCAQCgUAgEH6a7PnrlmsCqlarwWBwbW1NrVZbLBan0wlPAaw6R/iJzMZeMgxTq9USiUS1WjUajSqVSqvVymQyMkN7W2CerNFozp49e/nyZafTKZFI3vZGvQXY+dXm5ub29rZQKJybmxsZGXmXU4STySSPx2u32y6XCx2vXrfbpVAoKJVKk8k0ODhosVjUavVrXd0RqFarsBmOjIyIxWKJRMIaowg/WZrNJk3TzWZTJBLVarVSqYTQn3w+L5fL5XL5+Pg4TdMnIrLgm06lUlmt1oGBAaVSeaircq/EPfIVSSAQCAQCgUA4Aq8WgCiKqlarsVhscXGxv7/fZrM5HA6KokQikVKpNJvNKpXqyLEarVarWCwWCoVCoTA4OKjVahUKhUwme+8ebx5ZC3sHwYyoWCxeunTp+vXrg4OD77Lq8bphGObRo0fhcFgkEl2/ft3hcLyzNUQCgWBzc7Ner2cyGbfbrVQqX+vq4GvIZDLIbrdYLDqd7l3TgAQCQavVqtfrKysrZrOZpunXfVgI7wU8Hk8ul8MdhnYErVar2Ww2Gg0ERZnNZqFQeCKd13k8nkwmczqdp0+fHh4eViqVewU5syag7r92WIFeX10ngUAgEAgEAuFHzH4/bdk0aJiAIpHIysrKwMCAw+Gw2WzoOT02Nnb27NmBgQGFQnG0LWg0GplMJpPJ5HI5p9OpVCpFIhFrlX8vEAgEYrFYr9fDxPQuJ8UchGazmc1mNzc3U6nU1NTU559/Pj4+jnimt71pbxQ2PnlnZ2dtba1UKo2MjExPT6vV6nfzUPB4vFAolE6naZqWyWRarfa1VvBhsprP53k8nl6vVyqVKKU58ZUKBAKRSCSRSI5wZfF4vGw222w2S6USn89Hhek7K+ER3gzQfVqtVm9vb7PZ5PF4UAlRkmyz2VDSeCIKCzobCAQCu91uNpvxXbnXDeRQNxYyjAkEAoFAIBAIh2W/n5vcAMtcLheNRpeWltxud19fn8lkoihKpVI5nc7r169funRpaGiI+3v04D9kG41GIBCoVqsMw1gsFq1WKxKJ2u32Ycs0MEuUSqU0Tb/h+Xmr1cIz3vHx8VOnTvX19SFR4sQTQLkN1F7rEkqlUigUunHjRrVanZqa+sUvfjE2NoaqoncB/kvezOpgAorFYkKh8Pr16z09Pe+mANRutwUCwZMnT3g8ntVq1el0r9u6xTCMSCRKJpMKhaK3t1ehUAiFwhOfl8KsYTQaLRbLEepDRSJRKpVqt9v1el2lUsnl8tfUE+0g/Jisgu8vGAyVSiWZTBqNRqFQKJFIBAJBo9FgGCYcDut0Op1Oh8F2TBMQBCCDwSAWi2UyGQps8QXR/WZ86+31p47vxDd5DyQQCAQCgUAg/Dh4xRN1JMLg3+l0OhQKzc/Pnz59emNjo9lsSiQSNH4+deoUirk2NjYwC0WCZrPZrFarrVaL21oeYCIkFAqh12xsbPT19clkMrPZrFAoxGJxpVI5uAYkEAgkEolGo1EqlQzDZDIZNJh/Y2EfqB2gafrUqVMURXk8nhcvXqTT6Uql0m63WS/J0R4ps/NVJLwcYVH4FKoG2CVQP+zI1kGpVNrY2Pj2228vXrxoNpv/7M/+7NGjR48fP45Go81m8+Crxvg5gqK3Fxg56NNcLpfr9fqJLHZX2AzXdDq9uro6ODio0WgmJyfD4XAqlTrgHnFP3+vbVIqi4GKIRqPhcNjlcvX29q6vr5dKpeMcov03vtFoNJtNGBwMBoNWq0Vu7sme9GazqVQq3W631Wrd2Njwer25XO6AS2YYptlsosbHYDDweDw0/O4+Jq+8Io4PiuZwuCBAdN8YCQeBPVlHO2s8Hi8ej7darVKpZDQaUcIMs1i5XObz+Vqt1mAwnMimogkdBrBIJMrn89Vqtftt7I7AWNddI9ZdGsYwDE3TtVrtRLaTQCAQCAQCgfBT4BUCENwieASazWa3t7c9Hs/XX389MzMDbahUKu3s7PT19dnt9v7+/p2dnWq1qlAorFbr8PBwuVze2dmJx+PFYrFer3O9JyKRSKVSmUwmsVgslUrb7TZChSwWCyZIh/pNz+fzZTLZ6Ogook+2trZWV1eDwWCxWMQaX7cSVK/X4/H48+fPK5XKzMzM1atXT506defOHa/Xm8lk2LcdTQN6pe6Dx9QSiQQzmXq9Dt2tYwn4OLsE9hXucth/Q0d79OiR2WyuVqtisfjDDz9UKBQPHz7c3NxsNBqvnHoJBAK5XK7RaDQaTbvdLpfLiUSiVCodc9LLMIxSqezp6RkeHs7lck+ePCkUCm9gIv3o0aOPP/5Yo9GMjIw8fPgwlUq97jVy4Z4pVgJjTzdAS6NsNvvgwYOxsbELFy48efIkmUweRwBix95elMvlYrGoVqsrlYrBYGi320KhUKFQaDQaVHfm8/lDXX2w8onFYh6PV6lUMNJyuZxQKLTb7UNDQyKRaHFxMZvNskeDXX73tJk9aFDHLBZLq9WiabrVanXoU3gnXIQoZKvVauVyuVQqHXzj998vOEHMZrNGo6nX65FIZGdnp1arHUpRPQ7d1+z+V/FeeTRHWCnWIhQKUceHpwJHXjL7WIJhmCP4uXg8nlQqTaVSrVYrk8kYDAaFQlGv18VicT6fLxaLRqNRq9WaTKZcLneE5eOGjGsHhYdGo1Gn02m12mAwqNFootHoYY/tru9stVp7xQkRCAQCgUAgEAjdvDpTg2sC2t7eXl1dffr06QcffCAWi+PxeLVa3d7ebjabDoejr68vEon4fD6pVOp0OkdHR41GYyAQ8Hg8oVAoEokUCgV2voGUzcHBQaPRWK1WVSpVrVZTq9XQgDwez6GEEpqm1Wq1Xq/HU1aVSqVUKhUKxfr6ejqdfjOP2RuNRjKZLJVKmUxmdnZ2fHz8L/7iL+7evfv8+fNwOPxa53h4wmwwGAwGg0gkQmh3LBZDYd0BFyISieRyOaoe8Gy8XC4XCoWFhQWKomQymVKpHBkZUSgUT58+9Xg8pVKp2WzupUkJBALogAMDAyiyKBQKwWAQqtxevrAD0m63FQqFy+XS6/VSqfT+/fu5XK7VamF6yePx4Pg42sK7wTGs1WovXrywWCwqlaqvry8Wi7EaBAufz0cNFAJl8UH2+CCaRyQSNRqNcrl8wHZU7ASPlWLFYrFarTYYDEqlUiwWo3tROp2G46xYLEajUZ/PZ7VaR0dHI5FIrVY7ztFgbVBYO6a1mHhDVclkMs1mUy6XQ+NAcyW3263Vand2dlZXV+GW4vF4NE0j3otVrDqOAKx88F8oFIpsNhuNRnO5XKFQ8Pv9RqNxenp6amqqWCx6vd5SqYQ1UhTVbDah6XTMhzHGWq0WLGN8Pl+hUOTzeZlMRlFUuVzmSqUikQjTfp1OJ5fLS6VSPB4PhULFYvHIRw/w+XzkT/f09LhcLsjc4XB4cXExGo0WCoUDjoe9jCE4TezhZRgG5qwOkYUrBLNL6xaCKYoSCoVisRidsDB+MISOIDewGiJ7cmUyWalUgt3mCOIFK9IhvxlGqkPdTDAaq9UqFtVut+FmpSiqVCrl83nc6JAGXalUqMPsOHZTJpPRNA0HqEAg0Ov1EolELpfjOAuFQlQ646R3aJF7mYBAh3JEBCACgUAgEAgEwsF5tQDE/W2azWZXV1f1ev3Q0NDs7GwoFAoGgz6fb21tzWq19vb2JpPJWCyGROT+/n69Xo8JiVarlUqlGxsb0IDwE1av1w8MDPT39wcCgWKxmM/noQphhnBwhwXSduRyOZ6uJxKJYDAokUjGxsZUKtXTp08zmQw7PcAMlt016kTNQaiDW1paCoVCGxsbf/7nf/7ZZ5/ZbLZvvvkGRowjr4vr/uheSKvVksvlAwMDc3Nzer0eUaY3btzwer35fL5jCdxldsz9NBrN2NgYfBypVGphYSEej6+trSHVKJFIlMvl8fHxsbGxf/3Xf8XEHrPu7oVjyT09PVeuXJmcnIzH49FoFEEY6XQ6m83mcjnM3I5wTPL5fCaTabfb09PTGo1ma2sL3b4FAoHZbJZIJK1WKxQKobXzYRe+K9VqtVwuP3jw4E//9E8nJiaePXsml8tZbwu3wk4ikVgslmq1ms/noRCxf4U1ZnJykmGYnZ2dzc3No02AKYqy2+1TU1N2ux2al1gs3tnZefHixbNnzyAAbW1tDQwMzMzM/OEPfziRI0BRFGxHUFJyuRwOb6FQSKVSXq/3r/7qr77//nsYZ9LpdLPZnJmZQXz4nTt3MA4lEonD4dDpdPV6PRAIYAx0rEUqlZrN5snJSYvF0mw2FxYWlpeXt7e3A4EA0ujPnTvX39+fyWQ2NzcpipLL5WazGSIR3DrI9GUXiGGWTqenp6cXFxex/X19fTqdrlarLS8vsxqxUChUq9Vnz5612Ww8Hi8cDvP5/EqlciK1WkKhUK/X9/T0oJFctVo1mUxjY2M6na7dbgeDwVAoxK177XaIQBQQCoVc+xKbGoOxZ7Vaobfmcrl4PJ7JZPbfeKFQCCGvw2ImEok0Gk1PT49MJqtUKtFoNJVKsTeTo4GgNPQQYBhmY2MjGAwezSBmt9t7enpUKlUul0smk9FoNJPJHPx6xwgRCoWlUkmr1ZrNZo/Ho1Qqa7VapVJJp9OJRMLpdEqlUrlcvuti9+nVhacRDofDbDY3Go1oNIpkOrlcXi6XcddFHpBMJms2m/Acdch/bDuwjoULBALYY1F0zL5ONCACgUAgEAgEwkE4UFcdPC/F9CAajT59+lSr1f7iF7+QSqXlcjmXy6XT6eXl5StXrrjd7lQqFQ6HlUplq9VKJBIPHz4Mh8MURTmdToqigsFgOp2mKEqpVEokEoPBUCwWY7HY2tqa3+8vlUqzs7OYw8Tj8YO7ZuBeUavV9Xo9FotFo9F6vY4qGK1W+91332WzWfxcRqGZVCpFSRpFUfV6/Zg5KVzwq71YLK6urtbr9ZmZmaGhoa+++urWrVt+v3+fGRR+3KODEoJLOvwRNE1LpVKBQIBKH3bChofJarXabrczDAPhTCqVTk9PZzKZarWKlBaFQqFWqyGu4SihNI8tcECj4omJCYvF4vf7k8kk+xB7aWlJKpVqNJpMJvPdd99NTEx8+umnTqfz7t27wWBw19MEB5BGo9Hr9el0emtr69mzZ7FYrFwua7Xa06dPFwqFlZWVcDhcLpePcJxjsdjz589tNpvNZjt79mwsFoMtqKenZ3R0lMfjeTye+fl57CDSpjBlYhXAfRJquD4X9kVExv7+97+/fv36xMSE1+stFovFYhFTMngQYMUaHBx0u935fN7r9a6vr6MLFUVREomkv79/fHx8YGCgVCp5vd6lpaX19XWuQNlNh40IaTt9fX0zMzM9PT3hcHhtba1WqymVSigXi4uLpVIpnU5nMhm9Xj87O3vr1q3jTxGRz2W1Wk0mk0wmy2azfr9/Z2cHjglcwr29vXK5XCKRVCqV5eVluVw+Pj7ucrnS6bTH42m1WqgMtVgsSFrZ2NiAh4g97FKpVK/X22w2RDUzDIMhlM/n8/l8KBSCvUitVhuNxnQ6ncvlkHjtcDiSyWSz2RQKheVyOR6P53I5XPLwW9Xr9VwuZ7FYlEqlXq+3WCxjY2NQOp49e4ZTgGtKp9MNDg6i4hWKjFgsPtoo5Z5EmF96enrkcnk0GvX7/ViXy+XS6XQOh+PevXtbW1uIdIEzRSAQoHiWeunyg0eyXC5ns9l8Ps8eOvYWrdfrp6ennU5nrVaDDO3z+VKpFFpcUZyaKciRCN3H2GblSIFAoFKpMFb1ej2KNwOBwMbGRjabPYKQjdELB5nBYLDb7ZAwqtUq6lV3VVK6r0GKoiBXqVSqiYmJ06dP12o1aKkrKyuBQIC91tiFcK93tpAWi200GiqVCnV5RqNRIBCUy+VyuQzJTyqVoqWjUChEHSJ7EeFejVJl5Emjizz2ETHPQ0NDExMTarV6dXU1FotZrVa5XA5duFariUQinU43NDQkkUhisdj6+nosFoMYyt1fyHPYWmh/MpkMlwa8fhDQiQBEIBAIBAKBQDggB22rzMoNjUYjFAp99913mM7FYrFcLpdIJPx+/5kzZ8xmc09PT6FQwHNa+PPj8bhSqRwfH3c4HCqVamlpCdM2uVxO0zRN0ygHwIxlYGDAYrH09/eHw+EDpmOgEAAVEGjfCxlFKpUODAzY7fZsNos5Hub/Op1uYmKCpul2uy2TyfL5/Obm5vr6erFYPP7PaHYJ7Xa7VCr5fD65XI5eabdv337x4kW36QPHFnU9FotFoVAwDAMfB7YZbxMKhVar1WazKRQKVFE1Go16vV4ul9vttkql0ul0JpMpGAziETEmnMlkstFo2O32vr4+h8OBnKBWq7Wzs7O+vg7vFbanUCjgMbXdbt/e3oY7A9ObYDBot9sVCgWq83K53OTk5Llz5/BXxEJ3TEKwbYlEQq1WY4a5vb29tbWF/Z2amjp16hSiWEKhUHcp0CvJ5/Nra2srKyt2u31iYuLu3buNRkMul2M6ZzKZLBZLLBYLBAKtVkutVqvVaoqiUK6IllLlchnP3imKQmMmDIl2uy2VSrVarVgshmENT+kbjUYqlbpx48bZs2cnJiYQhJTL5eRyuUKhoCgKeVj1ej0UCp0+fXpiYmJubg4GFghqCLrq7e3FtNPlciEPZXFx8eDFerhktFqtVqsdGBiw2WyxWOy7775rNpsY7RaL5ebNm4FAAHsxMzNz9+7dYxpYMJE2m82nTp1CZRA0l6dPn25ubsZiMRSCuVwupVJJURTDMJFI5O7du7FYbHZ21maz7ezspNNpo9HY399vMBjC4XB3yzA0Y7Lb7YgG29nZyWQy6XS6WCyyN59wOPz48eNr166hzDObzcL48yd/8idra2uNRkOn06lUKr/f/+TJk1AoBImENdfg+oLug9T5ZrMZDAZRQlir1WBy/Pjjj2maFgqF4XA4nU4fv5wQHaa0Wq1cLjeZTC9evNje3k6n08PDw1NTU06nU6fTIb27VqvhbmC1WrVabaFQ8Hg8QqEQulV/f39PT49Op1tZWfH7/ZFIJJfLsWVElUolkUjU63WHw+FwOJCF7/F47t+/n0qlcOeBi6per3MdSTweLxQKPXjwAKoZboz9/f0XLlxoNpvhcLhUKp09e9bhcGC9h0ro50LTNGSXUCgEyQNjoMO0BbFDoVC0Wq1KpcJ+C2D7m80m6vJkMtmpU6csFsvAwMDU1NT9+/fhvmTrAbEQpVIpEomg/0JvwhcBn88vFAozMzOFQmF4eHhtbQ23skQigTpNh8Px4sULXKQod4Xig8g5o9HY09MjEokKhcL29nYqlapWq3w+H6d4aGjIZDIJBIL+/n6FQgEzUSwW4/F4jUZDLBb39PRMTU1ZrVacoydPnvj9/nQ6jVVQLzV0sViMglwejwfdU6vVMgwTCoWgbOLGSzQgAoFAIBAIBMJBOKgAxHWkVyqVzc3NXC7ndDpRW5FOp2maXllZ+fnPfx4OhxOJxObm5qefftpsNnt7ezc3NxUKhUqlOnv2rFqtbjQaS0tLeACrVCrb7bZOpyuVSigeSSQSFotlaGgoHo8XCoVcLneQzWs0GpFIBM//4Xxpt9uY9uv1+l/84hewHeXzefyIN5lMH374IbKNBQLBxsbGd999d+/evSNPbLppNpsoSYvFYhDL/vIv/7LRaKyurpbLZdhG+Hw+ojooiuLxeBqNxul0ulwuiqIKhUIoFFpaWorFYugjA4ViYmLC6XQKBIJ0Og3zRTQazWazWq1WpVJZrVaRSPT8+XOtVou4ZdQHGQyGM2fODA8PSyQSTBqhl4nFYniy0Ml+c3Nzbm6uXq/DmZVIJNCwplqt+nw+vV5vNpuHh4fv378PZeTChQv1ev3+/fvhcLg7fqVcLmcymYWFhWvXrmk0GlgzGIap1WrFYlGpVE5PTycSiUKhkEwmD3t4kVEdCARCoZBerz937twf//hHhUIhl8sxXdfpdHNzc5APlErlwMAAbFA+n08sFkMo8Xq9KEIRiURI6BCLxRCAnE6n0+lst9uJRKLZbEYikY2NjWq1mkgkvvnmm7/6q7+6cuWKQqGIx+MoeFQoFM1m0+/3P336NJVK/eEPf7hy5conn3xy6tQpv9//+PHj+fn5WCwmkUgajYZQKHz8+DES02Uymclk2tnZOeDA4/P5KpUKUU2QVqenp9fX17///vtgMDg8PDw5OXnp0qX19XWv1zs3N2exWKABHfYIdyASiWQyGUKm1tfXoXy53W6BQMCaEbLZ7MDAwOrqKoJ1stnsxsaGUCg0GAxqtRqhUWq1WiqVFgoF2MG40iEqsIxGo8PhyOfzqVQqGAwWCoVisVir1fA2hmHS6fTa2ppWq4UljWGYUqlULBbPnTuXSCR4PJ7FYnG73Waz+fbt2z6fD6sIhUL5fL7ZbBqNRszw+Xy+UqlUqVQWiyUej2ezWVS0bWxs3Llz5/z58xMTE4FA4OHDh8ev/8LFi3MHCRKeEdSsqdXqdrsNgw/0XNaI1Gw2eTxeKpUymUyQdQYGBlwu1+joKLSYlZWVra0tfAqmy8ePH9M0PT09bTAYbDZbb28v9EpEtrG5OZAh1Gq1QqHQ6XRut5um6UePHmHAt9ttmqZ1Oh3DMOvr64lEotVqwawkEokQAXbYg4DDSNM0PDJwMjIMgyMDLxjro6Fp2mw2y+XyZDKZTqcZhoGJD/6jdDq9uLgIjQwmJpvNZrVah4aG5ufnMWwgjpjNZmiOCP0pFoupVCqZTBYKBeSFicVit9udyWSSyWQ8Hm+327VarV6vq1QqhUJhNpux0mq1WqvV4LiBvG6z2SYmJqxWa6vVCgQCKysra2trpVJJJpOpVCqIfciQNhgMkBrr9TquFESn4w7MMIzD4YAkt7q6yn0OodVqnU6nSCSCfockaYFAgFsWOu6xX82sxYlAIBAIBAKBQNiLgwpA1A81IDwmzWazeHLbarXy+fz6+vr29nZfX188Ho/H4+vr69PT09PT07CcDAwMGAwGqDP1er1QKODBtUaj0el0fX19fD4fQTPJZLJSqdhstmQyiVn3K+fGDMPE4/GVlZW+vr6RkZHPP/88nU4jyEYoFLpcrk8//fTevXuRSAQzmXq9rlAo+vr6EJCh0Wgoikqn0ysrKycSHIPHvDRN9/X1QZwql8sffPDBtWvXWq3W+vo6wzAqlQoZFmwFENJMtFptKpXC82QYdvBAm3qZZavX6yuVikwmq1ar1Wo1lUrlcjmaphUKhcFgsFgsNE0Hg0GYgxiGMRgMIyMj4+PjSqVybW3tyZMngUCgXq+bzeaJiYlTp049ffo0EAiUSqVgMPj8+XOz2Tw2Nnb27Nl0Og1ZrdVqpVKpSCSi0WgMBoNOp9ve3n7w4IHT6Txz5gyPx7tz5w7ygLhVG+VyORwOP3nyZG5ubmpqKhKJJJPJnZ0dVNOoVCosDY6tI5gsSqUSvCcSicTtdq+urup0OoVCAduRwWAYGhpaWFjw+/0ikQh1Ya1WKxgMUhQlkUg++eQTi8Vy9+7d9fV1jUaDR+tYglwut1gsLpfLbDZnMhk+nx+NRn/7298uLi7m8/lbt265XK7Lly9//vnn2ClM6kwmE+qbbt++vba29vvf/14mk129elWj0Xz88cdTU1PLy8uskIcZLPTNarV68JlbpVJhdYTt7e1SqWQymQwGA03TkUgECehnz56NRCJra2uff/65xWLp7e199uzZ/nlD7X3bvTMMUy6XYdaArczr9dZqNYvFQlGURqNBWyWVSgU/FObzuMAx0ur1OkxniURiamoqFovBF8Y9741GQyqV2mw2FDPG43HETiGBmI28QfD8yMgIZuw4/rlc7uc//7nf7/f5fE+fPv3ss88uXrwoEokymUw4HK5UKjs7O4VCYXBwENPmarVqsVh0Op3RaGw0GmzbwWq1GgqFfve739lstqGhoV/+8peo0DlmCRjknkQiYTQa1Wo1oogg+pjNZgxXpDVhN6vVai6XGxsboyhKp9PNz8/b7Xa40pBYfO7cOavVOjY2NjEx8S//8i+BQACRxjRNozVeJBJBTPjp06ehHD1//jwajeIeIpFIcL4ymUwkEgkGg1NTUxDKG41GOp1G9nYmk/noo4+ePn2KwzI8PGy32+VyOaThI+hi+Xyex+MhX1mv16+trTWbTZSX6vX6UCiEDcCdhMfjnTlzJpfLLS0tURSFxPednR1Ih36/H8E9ZrMZao7Var1y5crAwMDi4mI6nS4UCvV6XalU9vb22my2fD5fqVRQgioWi2OxGPtdgKz0jY0NhmHwtmQyOTo66nK5/H4/avFKpdL6+nqpVMKIRTA2ovHhKDSZTHK5fHFxETomOtkVi8WdnR30u0Q5aqFQqFQqpVIJVbE4BYVCQSqVDg8P12q1lZUVNly/XC5brdaRkZF6vR4OhxmGMRqNCFDDlrCXLb6a31g7OQKBQCAQCATCe8oRBSDqZR9f9n9zudzy8rLZbP76668HBgZqtdrt27f7+/tdLldPTw8m6uFwGBmrKpUKSSWLi4tff/01jDmJRKK/vz+Xy62ursbjcUwDuoMw99q2crl8+/ZtdJtyu92NRiMYDGKe+dFHH33xxRcqlWp1dXVlZWV9fX1zcxPCxIsXLwQCAXqWTU9Pb2xsnEgYEESQQCBw/vz5np6eeDwOGeKTTz7BrCMajbpcLpfLRdP07du3o9GoUCikadpoNCqVymAwuLOzE4lEIA0g9wdJE5FIZHp6ulAoLC0tRSIRBCrXajWNRpPNZs1mc7lcFolEyWQyEolg2iyXy3U6nV6vj8fjwWAwEAikUimtVmuxWGZnZ2Hr+F//6381Go1arXbnzh2ZTHbt2rVf/epXhULhzp07Ozs7aNsUDAZdLpfRaDxz5kw8Hg+Hwzdu3Pjyyy9nZ2dNJpPP50P0bDAYRJ4IRVGZTGZ5efkf//Ef/+Ef/uHnP/+5xWK5desWG+zSaDTcbvfjx49RIHOE41woFMLh8NTUlE6nu3DhQjQaFYlExWIRPbAUCsX4+Hg8HofANDMzk8/nDQZDIpFot9uZTOaDDz6Ix+NI9NDr9Sj10uv1o6OjqIuBnJHNZicmJpDw7fV60+n0b37zm0aj0d/fX61Wt7a2IBLxeDybzTY3N5dKpbLZbCaTmZ+fR8ne1tYW4nhUKhUSoKVSaaPRQDTVPmlEuw6tWCyWyWSkUinaVL148SKfz0MrhEkhGo2q1ep0On3//n0oBX19fSsrK7vWiRykeAQ569AZYRBbWFjAHNtsNuv1epqmQ6HQ6OgowpVRnAWpS6/Xq1Qql8sVi8V8Pt+dO3cMBsPp06exzOXlZVZy5fF48IOoVCoETrNdutiJLlosKZXKYrHY39+PFlps77O+vj7EqXz77bcffvhhf3//2bNnb9++DTF0a2vLZDKdOnUqnU4bDIZWqwXziNFo9Pl8qBulKArBvb/5zW++/PLLiYmJv/3bv/31r3/NzVM/GtgGn8939erVyclJnCmTyYSu8IVCob+///nz52KxGAWt6Co4NzdnNBqRco0iL1S9pVIps9kMo1Cr1fr2229ho0O6sFKpRGVrrVZbWFiYnZ09depUu932+/2pVEokEiHty+VyQYvf2NhYWFg4e/bs9evXW62Wz+crFArr6+vr6+vDw8NXr15lGCabzQqFQrPZTFHUmTNnisUiPFOHOgjNZhOf0mg0iEkOh8MoOx0aGoJSiTpKPA9AGa9arS4UCgj8ymQyT548WV1dpSiqVqtVq1Wv1xsIBGq1ms1mQ2jR8PAwTI6Ii0LTMb/fD/cljFeo/fR4POPj4xqNBl3hUF+GojPcnRCnJZfLm83mo0eP5ufnUZZbr9cjkcjq6mo0GsU9Vq/Xj42NVSqVer0uk8nEYnEikYjFYul0ul6vo3tgKpVCxhMk9UePHlUqFbvdjnpDtVrtdDpTqRR0OoFA0Gw2i8WiyWTCloRCoe3t7WQyieg0yGQUJ86MbbhGIBAIBAKBQCDsyiEEIIqi8KuU2qNzVi6Xe/bsmU6nGx4eHhkZCQQCN27cGB0dtVqtqGLY3t6u1+uwtCgUikwm4/P5bt26NT4+LpPJisViqVRCN59gMFgqlVDUcMBtYxgml8vdvn17Z2dncHAQThCssVgsXr161e124wFvLBbzer0Mw+BndLFYHBsbGxwc7OvrGxoaWlpaOr4JiGEY6AXBYNDhcJhMplAotL6+7nK5Zmdn2+221+s1mUyDg4Nms7ndbt+8eRMPsUUikcFgwNQ3k8mgawzb67pWq5VKJUzhKpXK2toaZhcURaEwJxgMWq1WzNVR6oUdQYA0TdP5fL5arQqFQvS+sdlsRqNRKpWur6/fu3cPc8t79+4JhcKvv/76z/7sz0Qi0c2bNzHJyWQysVjMYrFYrVaXy7WysrK5ubm0tHT27Fk0ZsK+B4PBR48e+Xw+BLLG4/G7d+9qtdpPPvnkgw8+sNvtsVgMXXIqlQoqOGKx2BEOcrPZLJfLsVgMEh6KL1KpVKVSyWQy2WwW/by1Wi1SPJC66vF48vk8bCAqlWp6ehohrxRFZTKZaDQqFouHhoZ0Ol04HF5dXRWLxalUymKx9PX1nT59Gq3W/X4/es/DHJTNZqVSqcFgKJVKVqvV7Xbv7OzAVJLL5YRCodfrLRQKExMTX375pU6nazQabPerQ6k/GFrRaHRpaWl2dtZiscC2hiIgBMQioyeRSOTzeY/H88EHH/T29hqNRplMxiaGdCyQbQdOcdK+Ot4DRZWiKL1ebzKZIPHgnSKRSCAQrK+vm0wmp9NpNpuDwSDyUFB253K5crmc3W7f2Njwer3fffcdTdNXr16F2WphYQFlL8hpTiQSdrt9Z2eH7e/ObjDbGxtONx6PZzKZENOTy+VSqZTL5UKwSzQanZmZQeiyWq0Oh8MoTa3VaqdOnQqFQiijGx4e3tra0mq1qEvC7uAWFwgEHj16ZLPZPv74YwTrINb9CAMVlEqlcDj84MGDiYmJyclJiqJarRZUJ4lEIhQKh4aGtFot1Em83+/3/+xnP7NarTqdzuv1ejweuD9GRkbS6XS5XA4Gg1qt9tKlS8jYgisETpPJycnNzU2fz+fz+dRqtVgshnqyurpaq9VQagSXnMViefz48cOHD00m09TUFD6+urrq8/nu3bun0+n+8i//EvovLliRSHT69OmVlZVCoUAdposi3Fsej+fMmTOnT5/OZDLBYBAVmg6Ho7e312w2w8xVKBSQXi8UCsfHx4eGhtbW1lBL5Xa7oaL6fL5arYYKyocPH6LPIEVRbrc7nU6jDs5sNg8NDY2MjEAaRu4ShjrSxBcWFi5evKjRaFAXViqVqtVqNBpFtabZbIaOr1KpkBu1sbGBSsZms5lMJp89e+ZwOMrlMmrozGaz0+lcWVlBYZdarUYYOWJ9pFJpT08PbjVsMaPf75fL5VarVaVS4b6t0WgQFYTLB3WLFotFr9fXajWPxxMOh/EiVxhlL5DjlysSCAQCgUAgEH7EHE4A6uga3kGj0djc3Pz222+LxSKKBTwej9frRX+ubDYbDAZhx8DULpVKodCjWCyePn0aT4PD4XA8HkcqDfPDHtuv3LxWq4XPLiwsiEQiRBSjxXI8Hh8fH+fz+UjG2dnZSSQS8/PzEokEpU/lchnh0x6PBw9pjwnkCa/X+8EHH0xPT6+srASDwXv37v31X//15OSkTqcrFAoOh8NisUil0pWVlWw2G41GUR8xMTFx48YNtoUNOitBFcJc1+Vy2e32O3fusD6paDR69+5doVD43/7bf6MoSigURqPRSqXC4/EwfS0Wi263G0E5eFjtcrkkEgnDMDKZ7PTp05jfovzh1q1bAoHgb//2b7/88kuFQvHP//zPxWKxXC6vrq6Ojo4ajcbJyclAIJDJZJ4/fz40NDQ8PDw0NIQasbm5uWvXrv2P//E/Hj58iMZMkUjkX/7lX7a2tr744ou5ubnJyUk+n6/RaNB92WKx4Hn+YeHz+ZDzVldXv/rqK5qmEfn84sULhmG8Xu/IyAhSQiKRCCpKZmdn2bbfVqvVbDajbi4UCm1tbXk8HvSeO3/+fCaTaTab//7v/46cWrFYfP369ZmZGY/Hk0qlMJF2OBwGg0Gj0SiVSqPRODAwYDKZSqWSSqVyu906nU6j0VgsFtQbomNau93+m7/5G7FYjJCmo+mMrVZrcXHxm2+++fM///ORkRHUKMHP0tvb29PTI5FI+Hz+9va2Uql89uzZ+fPn79y5o1Kp9uoIfpDNaLfb5XL5/v37f//3f+90Ont7e1OpFHreo4oqn89/9913H3744dzcHBqT0TSNZBa1Wm02mxcXF7VabTAYXFhYQJHLp59+arfb//M///PGjRu5XA5ulO3tbY/HMzs7++TJEyQHsacbJ5Gm6Wq1ajQaRSKRVqtF9+6tra1CoRCJRCwWC6b3CwsL169fh8UmlUoVCoUXL16MjIw4HI5f/epXsVjMbrdXq9WzZ8++ePECgeLIHpZIJDKZTKPRIGXJ5XJ99tlnSI1BK/ojnDKQy+VWVlb++Z//+ec//7nT6SwUCvF4HPeiyclJk8l08eJFVHTiek8mk3fv3r169SpqbLe3txOJhEajWVhYQKczxKtNT09fvnx5Y2MjEAhsbm5C1E4kEogBCoVCbANHmUyGLHNUyNI0DbMevHvffvstRVHj4+Mwvi0vLy8vL7fbbUjkECPW19f7+/sdDsepU6fQ//FQRwDR+M+ePevv7x8YGEDpE0VRqNJSKpVzc3PI9kLsDrKN+vr6JBLJ6uoq9gXGJZFIxOPxCoWCTqfDVYCIn3w+n8vl8vm83+9XKBShUKjdbrtcLkQdIdCazd0vlUrz8/MajQaRaqhJRIPCx48fT05OIoOpWq1qtVq9Xn/69GnkZOM6QjUin89HtpRUKhUKhYi0g+jjcDiQtQTTkFgsHhgY2NzcRJ4RWqE1m00MOYqipFKpVCpFzL9UKkXfxkKhkEgkUPHn9XpxRtjkOK4GhAuEmIAIBAKBQCAQCHtxOAGIoiiGYbiNezpAxkqhUFhcXFSpVEjcRF8biqJqtRoKHzCXg8SztraWyWS+//57NHFPJBLpdBrFIFjmQaQfLrAMsCJOu91Op9O3b99eWlqSSCQw0QiFQgSOolLJ4/EkEgmTycQwDHSWE2kHBqPH5ubmzMzMuXPnMIH89ttvZ2Zmpqam0Kgb4SkXLlzAI/2VlRWn02k0Gj/99NMbN24UCgU84lYoFLlcLhaLQSfS6/U6na6/vx9iB7Y2FovdvXtXoVDMzc1dunSJpmmPxwMvUjQajUQiTqfz7/7u7zweD0VRIpEol8v98Y9/ZBgGzcW+/PLLR48ehUIhkUgkl8sjkcj//t//+/z58x9//HGj0fjjH/8YjUYhro2Pj0NAyeVym5ub//RP//T8+XOdTodWSr29vdPT01999VVfX9/Tp0/9fj/CvO/evRsIBH7/+9+bTCa9Xu9yuRDYMTAw4PF4tre3D3vM4RlJp9NQ/dxudzweT6VS0Pjy+Xw2mx0ZGYnH499///3Ozk4qldLr9ZcvX4Zeg0olnU4H90QikUBvNcw/kcSUzWZ9Ph+ytNvt9tmzZ6enp1GXlEqlFhYWJicnbTabWq2Wy+X1en1+fh5TelSFwD2UzWZjsRjDMJubm7/97W+TyaRWqw2Hw8hzOdroymazd+7cKRQK165dGxoaUigU4XCYx+MhhQe5ufl8PpFIRCIRl8s1PDy8vLyM9k8YmazAyrL/hYbCmYWFBVTNfPrpp3K5vNVqobE69hr9p4aHh8+fP+/1eoVCIXrP4WKXSCRisRi6mEwmQ77PhQsXDAZDvV5/8OBBPB6Ha+nhw4cTExNIkZ+fn0eJKLYB02YYdlBWIxKJkJKLojO0Ni+VStDXzGYzmkAVCgWv13v79m25XD49Pa3X66PRaCqV6u/vv3jxokAgMBqNsI81Gg2bzeZ0Oi0Wi1gshq8Esb7RaPQ4YUD1ej0ej9+8eTOfz4+NjcEhsrW1BSXlzJkzly9fhi8GRZf5fP4Pf/gDbkcbGxsbGxvJZBLhX0gQhxwQCoVmZ2fxkWKxGIvF4KbU6/Vut9vtdtdqNVyeUIRxTwgGg7du3YLVBYk/qDmdmZnBp3Au5ufnI5HI+Pg4Yqfq9fpXX31lNpvhASwUCoeynMAE9OLFC7vd/uWXX87MzJhMJkQjKZVKpVKJG6NAIEB/SY/HMzw8rNFoms0mfD02m212dtbpdCYSCUhCOIPBYBAZUpCHpFIpvn0SiUQ4HP7lL3+JtgAikQiiEsKeETCEvcOlgeKvpaUliGJCoRDd6K5duyaTyVCyirZ0KG9UKpXoHsgwjE6ng8sMjeRghkXSf7FYRCnZqVOnHj9+jAghmqYRP49a4Gw2C6mIoii00URGFU3TPp+vUqlcvnx5enp6Z2dnY2OjQ+thnX0oHDvyECUQCAQCgUAg/Lg5tAC0vwmIoihEV+TzealUyuPxIPp0twlngUMEbgLMYeBTOLjxpxtWEwF8Pj+XyxWLRVZ4wqSFfYiK+BskRnOTNY8JUopDodDMzMzs7KzH43n69Om3336bSCRGR0eFQmE8Hm+1Wj09PRcvXlxeXsZjZ51Od/Xq1T/5kz8RCASpVKrdbisUCvQtjkajOzs7q6urbrdbIpGYTCb2EKGlTiAQ+Pd//3f0Nj5//rxOp0un06lUanNzE/OQixcvomahWq2iSRNqEFBYgeohoVA4OzuL9smJROKjjz6iaToajZZKJThfxsbGlEql0+kMBAK5XA6VaHK5nKKoTCajUCiWlpYuXbqk1+tHRkZqtRoSqTED397eRqXS2NhYrVb7+uuvh4eHEfxxhCPcbrfX1tbW19cXFhYuX77carWg4KCezmAwfPbZZ3a73Wg0Li0tod7tzJkziFzh8Xher7fZbJZKpWQymc1ms9ksNKAbN26guRVUJFRO/eEPf0Adk0ajwSN6j8eDJCAE/bTbbdjcotFotVo1m81o79VoNNCGvFwub25uZrPZnp6eUqkEMfTIoyuRSDx48CAcDl++fNnhcPT396OREIoHEdPr8/nOnz9fLBavXLmyvb2tUChqtRpyo7jNhg4Iyl5+/etf/8M//MPAwIBOpwsGg/DjVCoVNNL65ptvVCrVpUuXkHeLrBNcX2iuhA5KME+Fw2H0qv/www8RQ57NZiORyK1bt+Ry+eeffw6LEMJ3i8VioVDIZrOIwsGwd7vdd+/eRYrT+vr6pUuX7Hb76dOnK5WKWCwuFApKpdJutz9//pzH42Uymfv37xeLxVAoZLPZEokEwpLGx8cHBgbgMYlEIqjps9vtMJgsLy/ncrnt7e1iscj2XTryWWs0Grlc7t69ex6PR6FQ8Hi8UqlUr9d/97vf5fP5mZmZP/3TP11aWsrn80ja3tzcDAQC6A6Wy+XK5XK5XM7n8xsbG2KxuFarwbK3urqqUqmgaORyuVqttr29/R//8R/T09NjY2OwaCUSiUqlgn5qCD8OBALJZBI2QNwTFhcXd3Z2LBaLQqFAZ8ZMJrO1tRWLxZBro9Ppbt68ee3aNavV6nQ62bC2A+4+gp9gJePz+R988IHT6cRImJ+fRwjOpUuXJBLJkydPcGn/9re/XV1dpWl6a2tre3t7c3MzGAz29vYKBIJWq7W8vExR1KVLl7766qvt7W2pVJrNZiGCSKVSxC37/f5//Md/tFqtiDHi1klh3N68eRNJQ6i3hV7z9OnTra0ttVqNSr379++fP39eq9WeOXNmfn4eCdBmsxmVa/AxNZtN9qT853/+5xdffGEymSDEezwen883MDBgsVh+9rOfPX78uFKp0DSNm0mtVkNoF3Km0BbNZDL19PRoNBq4YjHCJyYmrly5UiqVbt68mc1m2ZpE7ncWaQlPIBAIBAKBQNiLQwtA1KtMQNTLx7zoIM59ca/3wwbf8Wj9aNLPXttDdaVWs0DPwjac1BpZkKW6vLw8Pj4+Pj7u9/s3NjZu3Ljx/Plzg8GAp/d8Pr+np+fjjz+uVCrBYPCPf/xjPp//8MMPP/roIwTclsvl7e3tUCgEy9La2tp//dd/IVkJcyd2dc1mMxqN/t//+38DgcDU1JTD4YAzhaIouHs2NjZcLheieVZXV1dXV9l8E7lcDueUSqUqFApTU1N2ux2ZylqtdnZ2NhaLwT+1srIyNTWl1+v7+/u9Xi+CeNjzlc1msXC73a5Wq9FeHa4cGHMguKCjzdDQ0KlTpxYXF8PhcCQSOYIg0mg00Pa+XC4jdbXZbNZqtVAodPv27WKxqNPp8Kj87t27AoHgypUrfX19tVoNET/r6+uQS8LhMPrNQbH6t3/7N+RSwSkGX8C9e/dgImg2m5hkbmxsRCIRhUIhkUiol0G/cJFEo1EEM6MUEXnerVYrmUwioRbj7bBTNXamh0Arr9cbj8cdDgcm0gi3DoVCaH3F9oOz2+1Ik0kkEoFAwO/3wwF0WPtGrVZbX1//p3/6p8uXL6NNUiwW29nZgZsG6S3/8R//ceHCBeiD29vba2tr+CwUnFqtBlmtVCpFo1GU2kWjUYVCgSZWjUZja2vrm2++gSlmbGzM4XDAYbS5uQlrTyKRyGQyBoMB6d2JRAJ2sFQqNTIyMjo6iih0VL3B0ZbP53HwcSEYjUaKogqFAsMwT548cblcyHmp1+sQOovF4sbGhkwmg60mk8mweVvHBGpLrVYTCARwlrXb7Xw+D3/QuXPnbDabUChEPyzsbywWQ10bzhqCiiFnQw5DT3GcULyt0WgEAgFIRQhER7owKztiWMKEyA6tdruNxnbs3QD/xVnj8/nlclmpVJ47d85isaB/2V51hXvtO0VRzWYzHA5///334XB4dHQUZycQCLTbbbQmbLfbcrlcIBAgRT4SiSDBCqcAHj2VSlWtVpGDXqvVZmZmkKeGfoU4nmzzRL/fH4/HUcyFpwv4FqtWq/F4fGFhAQ3gG40GihNRZlUul2mahtmnVCrpdLqenp65uTmhUJjNZimKEgqFtVoNDdpFIhHy+CuVSiqV+v7775vNJtx5eAyQSCQ2NzfPnz/vdDqxa+VyGSf96dOnAwMDGGO456DLu8lkQisxJPf7fL5Lly5NTk5eunQpmUwuLy8nEgn2iQWr+xABiEAgEAgEAoGwF0cUWdjA1INwQC/PcSw/7zJarXZycnJmZkYoFN68edPv97MdatDSaG5uDs3C7t279/DhQyREuFyuiYkJt9uN6bHX6/X7/YlEApEoSK5pNpt44N/xcx+h0SqVCuGvpVIJoaqIE1Kr1UigKJVK+XweBSbtdpudT2KbR0ZGJicn+/r6NBoNWrPduXMHsoJKpTp//jxsQR6PB1mwXGECjgw27Kler8MF1rGRFy5c+PLLL3/1q1/95je/+fWvf724uHgETQSbbbfbkUy8tbWVSqVQ5UHTtEKhMBqNqBRD+yq32z0zMyMSidLp9NLSEuwemO+xvcaBSCTCjJrNaUZGDNI9oGdhZ/E6hi4bWswdz7t6yo42Sevu1461o7W2RCKBhIGUEJlM5nQ6//t//+9Xrlwpl8u3bt16+vSpz+fb3NxEudNhtwFd+UQikd1u7+/vN5vN1WoVGhDm4RRFicXi4eFhg8HQaDTC4XA2m0XiNY4Ywnc1Go3T6VQoFAKBAOpYOp1GWRPGAPrNO51Ol8sllUpxBqPRKNp+0TQ9ODj4xRdfRKPRhYWFFy9e0DQ9PT399ddfj4yMNJtNWN40Gk273f7tb3/74MGDra0t6qXai7R1nEeKojBODAaDUCiEOomjh/7fEErq9TqrEZ/g7BqjF//GLg8MDPT29tI0HYlE/H4/JBtsJzuuuKee4oyE7mGGRmwQInk8HhxArGTATddmP8J9sWNP0ZnL5XJ98skn169ff/78+b/+67+ura1B3j3sviNaS6lUajQaiGIIMkd2ezKZjMfjUIpR7sRuG7u/+IdQKNRoNIODg26322AwZLNZv9+Pbn0YeN3XIHtF44sMpVjsYwDmZb9L7ntkMllfX9/Zs2ddLhePx0MScz6fz2Qy8O/YbLZmsxkMBtn8e6lUajQatVotinBhQbVYLKdPn7bZbBRFFQoFVLDmcjlUMqbTaWhAIpHIarXiDry5uQlnFp/PR1nZxMREsVh89uyZz+fLZDLdse4dHlgCgUAgEAgEAgEcXW1BZ6WD8BMXgDA5x9PyYrG4vb3NPjOHdqBSqXp7exFeGwgEMFVAwK3RaFSpVOVyOZvNIq4VHgRMWjBD27UEAxNLWAxQ8oD3CAQCgUDAdn3ChJydLbDzQD6fj+bxBoMBlREIsmETndRqNTJBCoUCbBTdc0Xu/3JnlZjO8fl8m8322Wef/exnP6Np+n/+z/958+ZNzPeOdpAlEglN06gCYw8IZvsQtvDMHzVHkAay2Syrg+Cx/yvXzu4X87J5Vscx574ZC2SPNnfefrLTM/aocttCIxJobGzsL/7iL65du1Yqle7cuYPiIxT0ISL9CFccBD4E1kLBgbLA7hSSTVBQCe2PnX6zbgXMeFEThPHJWjbYiTdN0zKZTCaTIWcXZUqNRgMTcofDIZVKkfPSbreHhob+5m/+Znx8HFoSRVFSqTSTyTx9+vT58+dwurFrp14m5rKHjivhYXvwV5w7rqhHnagG1HFURSIRiq1g80FLcu7qdj1lXMGi40XsKSvvcndn1zd3L4f64WVrNpvPnTv3y1/+ks/n/+53v7t9+zai03f94P77233k8b9CoRDaa0dBLntBUS9PH/6B44b4ZBTDdkhdHXTfjihOgjKOMPtvdhWogHO73QMDA2g4GA6HQ6EQJHioSGjcjjghiiMZ4yRiyXK5XKlUSqXSRqMBqyzu6ngbZGh4oEwm08DAQKlUgq6NQmCJRGIwGORyOar/8vk8drNDzjsRtxqBQCAQCAQC4UfGUUrAAPtD/JVwf1Uf/22H5a3rSs1mE+3V8ZAZcwP8WMd/8ch3fX0dc2k2nbpSqUSjUTSKZpv+svOKjh/9HbBVb5gGsPMcFJJQL8s92Pdjost99F0oFCBXQTPCutiVIkeGO0fqEDW69RHqpUyjUCiQN0RRFKwfZ86ccbvd8/Pz3U+zD36Q2Ywn7lGCfQPv4fF42IVCoYDH6TgdrJHnIKvmDvsOpwBXROOON7wNp481MpysBoQFdo8HDCfMQsVicTAYDAaDCAlm33mEKw5DBaMU+8utr+Tz+ZjT7upMYY8VKvW47oyOuTrOHQJZsBYISUiRLxaLa2traGuF2XUqlfJ4PF988UUwGPT7/WtrayhQQnIztrBDKOFxwuYRvtuxJQeUBU8ErKVareKwCASCXX0cOGKHGj8d/cIPuzuQVxAQhn+gxPKjjz6am5vz+Xyo6zysCYgdtB1SBWQgag/fHMW5oFjJFc6darWaz+d5L1OuO97PvTy531xclYf7YscrrVYLgUGFQsHv9yuVSoFAgHh7xI1zZSOcOCy5Xq/DQ8ReaPl8vlgs4kXcfNjVcc84qtjS6bRUKsXhxd0b3crwbcLuZvc5RUbSYU4IgUAgEAgEAuHHz5sQgKgD6y8/PvsPC+YP+HfH7IJhGEx02Te3X/Y8Yp0IXFGDOtiB4uoU3SerQwCiujw71Mvn7RBNuBtGcWox9pqk7bo9aNLU398/Ojra09MjlUpFIpHFYhEKhRcvXlxYWIhGo93dqfah+0hy/7qXSafjYO762X1gXpZ97To/524Y+1f4cY4zCT/gVnVvRr1eRwJ6u91GuhOreVGHPIPda2StOtRuCuCun+Keso4JKteAxj223cINqyLlcjlW3ETClM/nczqdDx8+jEajKysrFEWhxKzj+LCLYqtZO07ZXnvxWsUg7rDEwdlL7nnldna8yLWH7CoecY9PxxtomkaJE6osJRIJ/Iw8Hm9sbOzMmTPJZBJWL+aHTrcD7i+70n32Zdet7TinkIHYIc36erjvZzgGIvaDHapfh3DJvUYajQarSLJ3kv11FkiW3ZIWV2Tk2ve4f4KVibupkMywGR1vpn544bBq1CsPJoFAIBAIBALhp8PRBSDqkBrQ2+IdFJW4Xif2AHaoA3tNh9jH5tSrdo1dCHdWwD4z7y4Z4H6QfbF7CsR9P3aB/dOus3TupwwGw8jIyMzMjNVqRdwvYm4ZhrFYLOPj4ysrK2wW+EHmgfu4xnYVaDp0H+ZlvMj+fopdp997jfx9lvO6h2L3qpGSG41GUbE1MDCAyk12S45sRGJroyiKarVa3FT4/Re4zyljfuio2n/XuGAzMplMPp8PBoNffPEF8rALhQLr6+mWO5mXLjkkMVO7zZm5to6OD74ZXrnevY7YXuw/dHddGsMwMplscHCwr69PpVK1Wi2FQgEByO12z87OPn78OJVKvfmaI+49ivqhyEVxrG17HTruIOR+dte7K3fcckUfrmzUMca4gk7HrbLjs3tpT7t+O3RrSfCLdTsx+Zx+ZwQCgUAgEAgEAkVRx5Jv3uRE6EdPh1rB/DBzZNd3ttvt/QW4XSfS3ZNh5iVH2/ID6ho0TUulUofDodPppFJpPB73+XzLy8sPHjzY3t7m8Xgul8vpdIpEosOu/WgVTLseim66a0beI+CRyWazm5ubCoVCr9efPn0awwac1IoO5ds6wikDe9nW2KUlEolcLre2tjYyMmIymTCWXnmW2S3v9mJQexcivb4hwXTFHu+zRlbT7Pgr/4d0fGqvs9+hkHLXK5PJdDpdvV6PRCJLS0vz8/NerzcajaKXn1QqRSrZkVXOXfXofUZpx91y14/vqqpzb6273gy5n+3eHfYj3M92/Jt6qbB3v86FXXj3qGOXyV0dNo+rPe06ttkjcOQLjUAgEAgEAoHwY+VYDiCq6+E/4YDsU7XU8U7WKHSQoo9u2BndwQsrOhxD3XPCbosQtcfUkQufzxeJRDqdTq/X53I5r9e7urqay+VgJbh27ZpUKrVYLFqtNh6Po+rnOAojO83bZwp08GNCHbjE6V0DzbMikQhN0waDweFwaDSaWCyGvx55L9gyE3YKeiJTTe4I5L7OdaJ1GDdYy0az2QyFQplMpl6vq1QqdPWiOJHY3I9QnBPaYYrpUA2oPVw2zEkHOXXvL7vx1L6X8K6vv9JFuNcyu1+p1+v5fH57e/vSpUsejycYDG5ubspksnw+bzQajUbj4ODg3bt3jy837Loxe9Ws7fp+quu8dLsg9/lsNx1Gm27ph32RHWP7KD7sR7r/3eE7Y35YNMr9xz7Fa907RUxABAKBQCAQCAQux32IfRAPBeHI7GoEOAIHn/l0F0mx/+ieQXF55TbU63WhUIj6kWq1ur29nUgkstks2jbn8/ne3l6NRqNUKk92RB1/acd0SL111tfX/X5/IBAYGhqyWq29vb14/UT2iB2ib+Y+sKvKwJ6gZrO5vLycy+V4PB7ERPavHanAuw5miuOz4L7hUMrLodjHiQO4+sJhF77PRw41pBmGqVQqsVhsYWFBpVLVarV0Or2xsfH8+fPFxcV2u22z2YaHh2H/eU3GqAPagtgN7v53h4R9kO3sEGV2VZM73tP9ItX1LbmrLaj9w+hoimPw6YDZ28XZvQvEBEQgEAgEAoFA4HICP9bf34nxO87JFunsuvwj/PWV+tE+H0TTnGAwmM/nKYqq1+vNZhOdqsLhcDab1el0EolELpe/ckUH5HVrE6/7HB2fdrudzWZ9Pp/P52s2m263G8rIyc7VXznPPLhSvOtUdp/ls29Gzvrq6uqTJ0+SySRFUTKZDE309lnyrovalddxog+iwhxnAt+h5x4ZCEArKytSqdRsNqtUqnq9nkgkAoGAQqEwGo0Oh0Mmk7GJWsdcHZd91LoOuuvd9q8gY/+EtwkEgg6rF9NVw8V9ha3bYrUhHid2ukMtYj/Ihbs7HVYjPiesjV0U2xag41Laf4QQiy6BQCAQCAQCgeUEfqkTE9Br4vW5TnZ9Kv7Kv+4vdnTPuzre3G63E4lEKBRC/DNN07VaDb3AY7EYTdP1el2v16NL/Qk+tX59z8DfWemnw+zQarW8Xu/6+nowGBwbG3M4HAqF4n30BbxSbms0Gul0+v/8n/9z8+bNVCrVbDZpmmaTgA9+vnZ98+uzt7Ar7fjHG2DXS7X7PRRF5fP5QCAwPz/f19fndDp1Ol25XI7FYj6fz2q1arVai8VyItfaQTbppGBXxG52x6o7XDlUVzQP1XWz6pByOha11ztfuSiKc2S6P7jX4WIr4Hb9K4FAIBAIBALhp8bJ/C4kJqA3wPHnh7tOq/gvo3y4k4qjnVD2+Tk71elWIqAB6XQ6tVptNBqFQiF6MMXjcT6fXyqVdDodZtrv/qTlUHU0bwC4GKiu09dqtcrl8vr6+tbWVqFQcLlcOp2Opuk3ueUnYsV6pZ+l1WpVq9WdnZ3bt28/fPgwHo/X63WucPPKQcU9Jh2jt/3DxkwnDrN3E7RjLpZ6laHvlcYoHo/XaDQSiYTH42m326Ojo263u91uZzKZSCQiEon0er1cLpdIJBRHKesQSg61wUfglV6hDpGa+1nW1MN9kX0P16TDTe3ZtZiL2s3Uw11U9/upH+41t9qre1Hc93D/sY+a/+7fSwkEAoFAIBAIb4bjhkAD/FQlvzJfN/yXUab8I6XPMl0Zz9RLVQgJKe3d+iJzP77/wvd5BWOjXq9vb28HAoG5uTmFQiEQCG7fvt1oNHg8XjablUgkAoGg2WwSQ9mRkcvlDMNUq1UYqUCj0cjlcqurq+fOnevp6YFf480f5BNMid7nDa1Wq1arJZNJtjan20ZBvSof51CvH5+jXc4nxUFWjWNYqVRCodDTp0+vXr0qFosVCkUikahWq7FYrL+/XyaTiUSicrlMvdSAjhw//IaPBsOJEqf2FU3au2Uw7/VX9g3du8NNT9/143vJQ+xWHVCvZ9/2dscYgUAgEAgEAuEd4cQkG/Lj8nXDVW2O+ZC8+xXuvGUvo9ChBL693lwul1dWVu7du2ez2T788MMrV66YzWalUimTyaLRKEVRYrFYIBCQ7NIjwDAMkrYlEgk3+4aiqEajkc1ml5eXt7e3i8WiTqfT6XRvstbmBHmlBsQwTLPZRGd6ro1iL2/aW4RrTeqo1jnBU3Miu9xut1utVjabXV1dXVxcVKvVH3zwweTkpEgkYhimVCqp1WqxWAwlpSMl50T24giwx7BbQOlgL/2aexYYTmNBbjw/97aMUbfXMtnXu6Ui1rvHPXrdW3vYOz+7FnI7JRAIBAKBQCBQJ+UAAsQE9F7DFumwM5+OYgrWPXSQpbGTJSyZXWar1QqFQv/1X/8lFosnJycvXbokEAikUin6f3m93nq9zp3/EGHxUFSrVYqiBAKBQCBgOK2v6vV6Mpl8/vz58PCwzWYrl8tsfu27eYR3LclhOfg27/rOd+dOxW7eu3wuWKABxePxe/fulcvlDz/88KOPPqrVahKJBIqbQCBAp7+3vi9c6w3OdavV6hhOHbrYcTb4CJ/lGo5Y/9E+QtWRRyy71wKBgLSEJxAIBAKBQPiJQwQgwg84cgnYQcAIqdfrHo8HVoLp6elLly5JJBKZTBYOh1OpVCqV6jBrEA5FtVqFm6CjiqRSqfj9/n/7t38bHBxkGKbRaPD5/Eaj8ZY287Vz2IrFt8iud86T3cJjLo0rTDQajXg8/vDhw3q9fvHiRZfLlUwmE4lEuVxmZeJWq/V21Vtucy52M3YtcWV2i17aq06Q1Yy4odGv3M19vhaZPTKY2K165VcqaxR65Wawmu/+byMQCAQCgUAg/Ig5YVv4+1hR8r7wY7LD8Pl8oVCoUCjQUchoNCoUinw+v7W15fV6k8lkvV4nD6tPHIFAIJfLjUajWCze3t7GjP1HM6gOwv7GIsJBgPzB5/PFYvHQ0FBfX5/dbt/a2goEAqFQqFarNRoNbiXUO8I+988j31oP+EGuyQhHj+uQeuWY5K6F/XfH92y3ekXtIQlx08EIBAKBQCAQCD81Tn4iJBSepKuIwPJjEoCol9NIgUCgUCg0Go1CoWi327lcLp1Od2QYHwqYX4h4tBfoFIYCMRzkH9OgeiVEADoRcPHyeDyxWKxUKuVyOUVRxWKxUqnU6/Vms/luCov7OGVOVgPaP2nomEVnx9SAUKB3hPUSCAQCgUAgEH4EnPxECLP6E18s4UcJnwP1MgMV8s2RZ0dsDO07OAV9d/iR6YmvhJV+iAZ0fFh9AVYgpLajfx+3+dp7NMDepAC060LYvx7cELR/2eA+ahcxAREIBAKBQCD8ZHktsyDMB17HkgnvBQfMpGDfzJ3JHH/qeKi1v3XYvJ73ZYPfU36aug/X63Gy+87KENy7fYe15MdnxGN3sKNt4j4X7yulJe7d7+AaENXlJ+rOEd/rTkhMQAQCgUAgEAg/WV7LdIiYgH4K7K+zHOqv3FBV6qenhpCyNcLr4/VpQCxsRRjWxe1v9TpWd0yOZvbhWhTxyoloQPuUcVG73UXxSnfHRnaTOg7+rktgyz8JBAKBQCAQCD81XtfzcGIC+rHS8XT6RCqJ9qpleL+8PMdBIBD81GQvwpvhDQhAgI03pl6mHf8ox/OuAtBrYtcbYLdjqOP1VxqOSI9FAoFAIBAIhJ8sRKMhEAiEt8z7m53f7eajOALu+6syvF31eX9nEPUqbeggGhAxAREIBAKBQCD8BPl/lV5F9+5asgEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(str(random.choice(images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0dfc0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://wandb.ai/cfrye59/fsdl-text-recognizer-2021-training/workspace?jupyter=true\" style=\"border:none;width:100%;height:420px;\"></iframe>"
      ],
      "text/plain": [
       "<Project cfrye59/fsdl-text-recognizer-2021-training>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_recognizer_project = wb_api.project(\"fsdl-text-recognizer-2021-training\", entity=\"cfrye59\")\n",
    "\n",
    "text_recognizer_project  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18b764e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wandb.apis.public.ProjectArtifactTypes at 0x7f8924314fd0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_recognizer_project.artifacts_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ac01e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://wandb.ai/cfrye59/fsdl-text-recognizer-2021-training/artifacts/prod-ready/paragraph-text-recognizer/v8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"720\"\n",
       "            src=\"https://wandb.ai/cfrye59/fsdl-text-recognizer-2021-training/artifacts/prod-ready/paragraph-text-recognizer/v8\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f89243140d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect all versions of the text-recognizer ever put into production by...\n",
    "\n",
    "for art_type in text_recognizer_project.artifacts_types(): # looking through all artifact types\n",
    "    if art_type.name == \"prod-ready\":  # for the prod-ready type\n",
    "        # and grabbing the text-recognizer\n",
    "        production_text_recognizers = art_type.collection(\"paragraph-text-recognizer\").versions()\n",
    "\n",
    "# and then get the one that's currently being tested in CI by...\n",
    "for text_recognizer in production_text_recognizers:\n",
    "    if \"ci-test\" in text_recognizer.aliases:  # looking for the one that's labeled as CI-tested\n",
    "        in_prod_text_recognizer = text_recognizer\n",
    "\n",
    "# view its metadata at the url or in the notebook\n",
    "in_prod_text_recognizer_url = text_recognizer_project.url[:-9] + f\"artifacts/{in_prod_text_recognizer.type}/{in_prod_text_recognizer.name.replace(':', '/')}\"\n",
    "\n",
    "print(in_prod_text_recognizer_url)\n",
    "IFrame(src=in_prod_text_recognizer_url, width=\"100%\", height=frame_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8843891c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model-1vrnrd8p:v41'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staging_run = in_prod_text_recognizer.logged_by()\n",
    "\n",
    "training_ckpt, = [at for at in staging_run.used_artifacts() if at.type == \"model\"]\n",
    "training_ckpt.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe9dfdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://wandb.ai/cfrye59/fsdl-text-recognizer-2021-training/runs/1vrnrd8p\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"720\"\n",
       "            src=\"https://wandb.ai/cfrye59/fsdl-text-recognizer-2021-training/runs/1vrnrd8p\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f894a3c8d90>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_run = training_ckpt.logged_by()\n",
    "print(training_run.url)\n",
    "IFrame(src=training_run.url, width=\"100%\", height=frame_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74695d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trainer/global_step</th>\n",
       "      <th>_step</th>\n",
       "      <th>_runtime</th>\n",
       "      <th>size/nparams</th>\n",
       "      <th>size/mb_disk</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>validation/predictions</th>\n",
       "      <th>optimizer/lr-Adam</th>\n",
       "      <th>gradients/encoder_projection.weight</th>\n",
       "      <th>gradients/transformer_decoder.layers.0.linear2.bias</th>\n",
       "      <th>...</th>\n",
       "      <th>gradients/transformer_decoder.layers.1.self_attn.out_proj.weight</th>\n",
       "      <th>gradients/resnet.4.1.bn2.bias</th>\n",
       "      <th>gradients/transformer_decoder.layers.1.norm2.weight</th>\n",
       "      <th>train/predictions</th>\n",
       "      <th>train/loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>validation/cer</th>\n",
       "      <th>validation/loss</th>\n",
       "      <th>test/cer</th>\n",
       "      <th>test/loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>13988756.0</td>\n",
       "      <td>56.064631</td>\n",
       "      <td>1654129282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1654129317</td>\n",
       "      <td>{'size': 34810, '_latest_artifact_path': 'wand...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1654129317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1654129343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "      <td>177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1654129361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trainer/global_step  _step  _runtime  size/nparams  size/mb_disk  \\\n",
       "0                   -1      0        98    13988756.0     56.064631   \n",
       "1                   -1      1       133           NaN           NaN   \n",
       "2                    0      2       133           NaN           NaN   \n",
       "3                   39      3       159           NaN           NaN   \n",
       "4                   78      4       177           NaN           NaN   \n",
       "\n",
       "   _timestamp                             validation/predictions  \\\n",
       "0  1654129282                                                NaN   \n",
       "1  1654129317  {'size': 34810, '_latest_artifact_path': 'wand...   \n",
       "2  1654129317                                                NaN   \n",
       "3  1654129343                                                NaN   \n",
       "4  1654129361                                                NaN   \n",
       "\n",
       "   optimizer/lr-Adam gradients/encoder_projection.weight  \\\n",
       "0                NaN                                 NaN   \n",
       "1                NaN                                 NaN   \n",
       "2             0.0001                                 NaN   \n",
       "3             0.0001                                 NaN   \n",
       "4             0.0001                                 NaN   \n",
       "\n",
       "  gradients/transformer_decoder.layers.0.linear2.bias  ...  \\\n",
       "0                                                NaN   ...   \n",
       "1                                                NaN   ...   \n",
       "2                                                NaN   ...   \n",
       "3                                                NaN   ...   \n",
       "4                                                NaN   ...   \n",
       "\n",
       "  gradients/transformer_decoder.layers.1.self_attn.out_proj.weight  \\\n",
       "0                                                NaN                 \n",
       "1                                                NaN                 \n",
       "2                                                NaN                 \n",
       "3                                                NaN                 \n",
       "4                                                NaN                 \n",
       "\n",
       "  gradients/resnet.4.1.bn2.bias  \\\n",
       "0                           NaN   \n",
       "1                           NaN   \n",
       "2                           NaN   \n",
       "3                           NaN   \n",
       "4                           NaN   \n",
       "\n",
       "  gradients/transformer_decoder.layers.1.norm2.weight train/predictions  \\\n",
       "0                                                NaN                NaN   \n",
       "1                                                NaN                NaN   \n",
       "2                                                NaN                NaN   \n",
       "3                                                NaN                NaN   \n",
       "4                                                NaN                NaN   \n",
       "\n",
       "  train/loss epoch validation/cer validation/loss test/cer test/loss  \n",
       "0        NaN   NaN            NaN             NaN      NaN       NaN  \n",
       "1        NaN   NaN            NaN             NaN      NaN       NaN  \n",
       "2        NaN   NaN            NaN             NaN      NaN       NaN  \n",
       "3        NaN   NaN            NaN             NaN      NaN       NaN  \n",
       "4        NaN   NaN            NaN             NaN      NaN       NaN  \n",
       "\n",
       "[5 rows x 152 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_results = training_run.history(samples=10000)\n",
    "training_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e432ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = training_results.groupby(\"epoch\")[\"train/loss\"].mean().plot();\n",
    "training_results[\"validation/loss\"].dropna().plot(logy=True); ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31b8cd4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19675205647945404"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 10\n",
    "training_results[\"validation/loss\"].dropna().iloc[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e8e61e",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5cce992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing training/simple-overfit-sweep.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile training/simple-overfit-sweep.yaml\n",
    "# first we specify what we're sweeping\n",
    "# we specify a program to run\n",
    "program: training/run_experiment.py\n",
    "# we optionally specify how to run it, including setting default arguments\n",
    "command:  \n",
    "    - ${env}\n",
    "    - ${interpreter}\n",
    "    - ${program}\n",
    "    - \"--wandb\"\n",
    "    - \"--overfit_batches\"\n",
    "    - \"1\"\n",
    "    - \"--log_every_n_steps\"\n",
    "    - \"25\"\n",
    "    - \"--max_epochs\"\n",
    "    - \"100\"\n",
    "    - \"--limit_test_batches\"\n",
    "    - \"0\"\n",
    "    - ${args}  # these arguments come from the sweep parameters below\n",
    "\n",
    "# and we specify which parameters to sweep over, what we're optimizing, and how we want to optimize it\n",
    "method: random  # generally, random searches perform well, can also be \"grid\" or \"bayes\"\n",
    "metric:\n",
    "    name: train/loss\n",
    "    goal: minimize\n",
    "parameters:  \n",
    "    # LineCNN hyperparameters\n",
    "    window_width:\n",
    "        values: [8, 16, 32, 64]\n",
    "    window_stride:\n",
    "        values: [4, 8, 16, 32]\n",
    "    # Transformer hyperparameters\n",
    "    tf_layers:\n",
    "        values: [1, 2, 4, 8]\n",
    "    # we can also fix some values, just like we set default arguments\n",
    "    gpus:\n",
    "        value: 1\n",
    "    model_class:\n",
    "        value: LineCNNTransformer\n",
    "    data_class:\n",
    "        value: IAMLines\n",
    "    loss:\n",
    "        value: transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d7bdc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Creating sweep from: training/simple-overfit-sweep.yaml\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Created sweep with ID: \u001b[33mwij1afrq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: View sweep at: \u001b[34m\u001b[4mhttps://wandb.ai/jobquiroz/fsdl-line-recognizer-2022/sweeps/wij1afrq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run sweep agent with: \u001b[33mwandb agent jobquiroz/fsdl-line-recognizer-2022/wij1afrq\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!wandb sweep training/simple-overfit-sweep.yaml --project fsdl-line-recognizer-2022\n",
    "simple_sweep_id = wb_api.project(\"fsdl-line-recognizer-2022\").sweeps()[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "035567bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wij1afrq'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_sweep_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "94de8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent 🕵️\n",
      "2022-08-31 17:30:40,324 - wandb.wandb_agent - INFO - Running runs: []\n",
      "2022-08-31 17:30:40,459 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2022-08-31 17:30:40,459 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tdata_class: IAMLines\n",
      "\tgpus: 1\n",
      "\tloss: transformer\n",
      "\tmodel_class: LineCNNTransformer\n",
      "\ttf_layers: 4\n",
      "\twindow_stride: 8\n",
      "\twindow_width: 16\n",
      "2022-08-31 17:30:40,461 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python training/run_experiment.py --wandb --overfit_batches 1 --log_every_n_steps 25 --max_epochs 100 --limit_test_batches 0 --data_class=IAMLines --gpus=1 --loss=transformer --model_class=LineCNNTransformer --tf_layers=4 --window_stride=8 --window_width=16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjobquiroz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mtraining/logs/wandb/run-20220831_173042-vijx0w87\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Resuming run \u001b[33mgood-sweep-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jobquiroz/fsdl-line-recognizer-2022\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/jobquiroz/fsdl-line-recognizer-2022/sweeps/wij1afrq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/jobquiroz/fsdl-line-recognizer-2022/runs/vijx0w87\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gpus' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'model_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'window_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'window_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tf_layers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'loss' was locked by 'sweep' (ignored update).\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n",
      "2022-08-31 17:30:45,470 - wandb.wandb_agent - INFO - Running runs: ['vijx0w87']\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                      | Type               | Params\n",
      "------------------------------------------------------------------\n",
      "0  | model                     | LineCNNTransformer | 4.3 M \n",
      "1  | model.line_cnn            | LineCNN            | 1.6 M \n",
      "2  | model.embedding           | Embedding          | 21.2 K\n",
      "3  | model.fc                  | Linear             | 21.3 K\n",
      "4  | model.pos_encoder         | PositionalEncoding | 0     \n",
      "5  | model.transformer_decoder | TransformerDecoder | 2.6 M \n",
      "6  | train_acc                 | Accuracy           | 0     \n",
      "7  | val_acc                   | Accuracy           | 0     \n",
      "8  | test_acc                  | Accuracy           | 0     \n",
      "9  | val_cer                   | CharacterErrorRate | 0     \n",
      "10 | test_cer                  | CharacterErrorRate | 0     \n",
      "11 | loss_fn                   | CrossEntropyLoss   | 0     \n",
      "------------------------------------------------------------------\n",
      "4.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 M     Total params\n",
      "17.189    Total estimated model params size (MB)\n",
      "Model State Dict Disk Size: 17.23 MB\n",
      "/home/jobquiroz/miniconda3/envs/fsdl-text-recognizer-2022/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:472: UserWarning: You requested to overfit but enabled training dataloader shuffling. We are turning off the training dataloader shuffling for you.\n",
      "  \"You requested to overfit but enabled training dataloader shuffling.\"\n",
      "/home/jobquiroz/miniconda3/envs/fsdl-text-recognizer-2022/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1931: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=25). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  category=PossibleUserWarning,\n",
      "Epoch 0: 100%|█████████████| 1/1 [00:06<00:00,  6.31s/it, loss=4.89, v_num=0w87]/home/jobquiroz/miniconda3/envs/fsdl-text-recognizer-2022/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:378: UserWarning: `ModelCheckpoint(monitor='validation/cer')` could not find the monitored key in the returned metrics: ['train/loss', 'epoch', 'step']. HINT: Did you call `log('validation/cer', value)` in the `LightningModule`?\n",
      "  warning_cache.warn(m)\n",
      "Epoch 99: 100%|████████████| 1/1 [00:04<00:00,  4.21s/it, loss=2.36, v_num=0w87]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2022-08-31 17:34:15,486 - wandb.wandb_agent - INFO - Cleaning up finished run: vijx0w87\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Terminating and syncing runs. Press ctrl-c to kill.\n",
      "CPU times: user 4.59 s, sys: 858 ms, total: 5.45 s\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# interrupt twice to terminate this cell if it's running too long,\n",
    "#   it can be over 15 minutes with some hyperparameters\n",
    "\n",
    "!wandb agent --project fsdl-line-recognizer-2022 --entity {wb_api.default_entity} --count=1 {simple_sweep_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7144b8",
   "metadata": {},
   "source": [
    "Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23919db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jobquiroz/full_stack_deep_learning/lab04/wandb/run-20220831_173702-2jvkno2d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jobquiroz/trying-wandb/runs/2jvkno2d\" target=\"_blank\">hopeful-thunder-1</a></strong> to <a href=\"https://wandb.ai/jobquiroz/trying-wandb\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hopeful-thunder-1</strong>: <a href=\"https://wandb.ai/jobquiroz/trying-wandb/runs/2jvkno2d\" target=\"_blank\">https://wandb.ai/jobquiroz/trying-wandb/runs/2jvkno2d</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220831_173702-2jvkno2d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import wandb\n",
    "\n",
    "\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "project = \"trying-wandb\"\n",
    "config = {\"steps\": 50}\n",
    "\n",
    "\n",
    "with wandb.init(project=project, config=config) as run:\n",
    "    steps = wandb.config[\"steps\"]\n",
    "    \n",
    "    for ii in range(steps):\n",
    "        loss = math.exp(-ii) + random.random() / (ii + 1)  # ML means making the loss go down\n",
    "        \n",
    "    with open(\"logs/hello.txt\", \"w\") as f:\n",
    "        f.write(\"hello from wandb, my dudes!\")\n",
    "        \n",
    "    run_id = run.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44678de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss not logged 🥲\n",
      "hello artifact not logged 🥲\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://wandb.ai/jobquiroz/trying-wandb/runs/2jvkno2d?jupyter=true\" style=\"border:none;width:100%;height:420px;\"></iframe>"
      ],
      "text/plain": [
       "<Run jobquiroz/trying-wandb/2jvkno2d (finished)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello_run = wb_api.run(f\"{project}/{run_id}\")\n",
    "\n",
    "# check for logged loss data\n",
    "if \"loss\" not in hello_run.history().keys():\n",
    "    print(\"loss not logged 🥲\")\n",
    "else:\n",
    "    print(\"loss logged successfully 🥞\")\n",
    "    if len(hello_run.history()[\"loss\"]) != steps:\n",
    "        print(\"loss not logged on all steps 🥲\")\n",
    "    else:\n",
    "        print(\"loss logged on all steps 🥞\")\n",
    "\n",
    "artifacts =  hello_run.logged_artifacts()\n",
    "\n",
    "# check for artifact with the right name\n",
    "if \"hello:v0\" not in [artifact.name for artifact in artifacts]:\n",
    "    print(\"hello artifact not logged 🥲\")\n",
    "else:\n",
    "    print(\"hello artifact logged successfully 🥞\")\n",
    "    # check for the file inside the artifacts\n",
    "    if \"hello.txt\" not in sum([list(artifact.manifest.entries.keys()) for artifact in artifacts], []):\n",
    "        print(\"could not find hello.txt 🥲\")\n",
    "    else:\n",
    "        print(\"hello.txt logged successfully 🥞\")\n",
    "    \n",
    "    \n",
    "hello_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4156211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Sweep jobquiroz/fsdl-line-recognizer-2022/wij1afrq>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb_api.project(\"fsdl-line-recognizer-2022\").sweeps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3723f217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
