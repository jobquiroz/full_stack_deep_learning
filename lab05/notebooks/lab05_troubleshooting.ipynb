{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ea281e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jobquiroz/full_stack_deep_learning/lab05/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()   # Verify where it is right now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a43e1cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution, go to lab directory:\n",
    "os.chdir('/home/jobquiroz/full_stack_deep_learning/lab05/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00d99a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trim trailing whitespace.................................................\u001b[42mPassed\u001b[m\n",
      "check toml...............................................................\u001b[42mPassed\u001b[m\n",
      "check yaml...............................................................\u001b[42mPassed\u001b[m\n",
      "check json...............................................................\u001b[42mPassed\u001b[m\n",
      "check for merge conflicts................................................\u001b[42mPassed\u001b[m\n",
      "check for added large files..............................................\u001b[42mPassed\u001b[m\n",
      "debug statements (python)................................................\u001b[42mPassed\u001b[m\n",
      "detect private key.......................................................\u001b[42mPassed\u001b[m\n",
      "black....................................................................\u001b[42mPassed\u001b[m\n",
      "flake8...............................................(no files to check)\u001b[46;30mSkipped\u001b[m\n",
      "shellcheck...........................................(no files to check)\u001b[46;30mSkipped\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!pre-commit run --all-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bb35805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trim trailing whitespace.................................................\u001b[42mPassed\u001b[m\n",
      "check toml...............................................................\u001b[42mPassed\u001b[m\n",
      "check yaml...............................................................\u001b[42mPassed\u001b[m\n",
      "check json...............................................................\u001b[42mPassed\u001b[m\n",
      "check for merge conflicts................................................\u001b[42mPassed\u001b[m\n",
      "check for added large files..............................................\u001b[42mPassed\u001b[m\n",
      "debug statements (python)................................................\u001b[42mPassed\u001b[m\n",
      "detect private key.......................................................\u001b[42mPassed\u001b[m\n",
      "black....................................................................\u001b[42mPassed\u001b[m\n",
      "flake8...............................................(no files to check)\u001b[46;30mSkipped\u001b[m\n",
      "shellcheck...........................................(no files to check)\u001b[46;30mSkipped\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!pre-commit run --all-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f4b1826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repos:\r\n",
      "  # a set of useful Python-based pre-commit hooks\r\n",
      "  - repo: https://github.com/pre-commit/pre-commit-hooks\r\n",
      "    rev: v4.1.0\r\n",
      "    hooks:\r\n",
      "      # list of definitions and supported hooks: https://pre-commit.com/hooks.html\r\n",
      "      - id: trailing-whitespace      # removes any whitespace at the ends of lines\r\n",
      "      - id: check-toml               # check toml syntax by loading all toml files\r\n",
      "      - id: check-yaml               # check yaml syntax by loading all yaml files\r\n",
      "      - id: check-json               # check-json syntax by loading all json files\r\n",
      "      - id: check-merge-conflict     # check for files with merge conflict strings\r\n",
      "        args: ['--assume-in-merge']  #  and run this check even when not explicitly in a merge\r\n",
      "      - id: check-added-large-files  # check that no \"large\" files have been added\r\n",
      "        args: ['--maxkb=10240']      #  where large means 10MB+, as in Hugging Face's git server\r\n",
      "      - id: debug-statements         # check for python debug statements (import pdb, breakpoint, etc.)\r\n",
      "      - id: detect-private-key       # checks for private keys (BEGIN X PRIVATE KEY, etc.)\r\n",
      "\r\n",
      "  # black python autoformatting\r\n",
      "  - repo: https://github.com/psf/black\r\n",
      "    rev: 22.3.0\r\n",
      "    hooks:\r\n",
      "      - id: black\r\n",
      "    # additional configuration of black in pyproject.toml\r\n",
      "\r\n",
      "  # flake8 python linter with all the fixins\r\n",
      "  - repo: https://github.com/PyCQA/flake8\r\n",
      "    rev: 3.9.2\r\n",
      "    hooks:\r\n",
      "      - id: flake8\r\n",
      "        exclude: (lab01|lab02|lab03|lab04|lab06|lab07|lab08)\r\n",
      "        additional_dependencies: [\r\n",
      "          flake8-annotations, flake8-bandit, flake8-bugbear, flake8-black, flake8-docstrings,\r\n",
      "          flake8-import-order, darglint, mypy, pycodestyle, pydocstyle]\r\n",
      "        args: [\"--config\", \".flake8\"]\r\n",
      "    # additional configuration of flake8 and extensions in .flake8\r\n",
      "\r\n",
      "  # shellcheck-py for linting shell files\r\n",
      "  - repo: https://github.com/shellcheck-py/shellcheck-py\r\n",
      "    rev: v0.8.0.4\r\n",
      "    hooks:\r\n",
      "      - id: shellcheck\r\n"
     ]
    }
   ],
   "source": [
    "!cat .pre-commit-config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b8281ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repos:\r\n",
      "  # a set of useful Python-based pre-commit hooks\r\n",
      "  - repo: https://github.com/pre-commit/pre-commit-hooks\r\n",
      "    rev: v4.1.0\r\n",
      "    hooks:\r\n",
      "      # list of definitions and supported hooks: https://pre-commit.com/hooks.html\r\n",
      "      - id: trailing-whitespace      # removes any whitespace at the ends of lines\r\n",
      "      - id: check-toml               # check toml syntax by loading all toml files\r\n",
      "      - id: check-yaml               # check yaml syntax by loading all yaml files\r\n",
      "      - id: check-json               # check-json syntax by loading all json files\r\n",
      "      - id: check-merge-conflict     # check for files with merge conflict strings\r\n",
      "        args: ['--assume-in-merge']  #  and run this check even when not explicitly in a merge\r\n",
      "      - id: check-added-large-files  # check that no \"large\" files have been added\r\n",
      "        args: ['--maxkb=10240']      #  where large means 10MB+, as in Hugging Face's git server\r\n",
      "      - id: debug-statements         # check for python debug statements (import pdb, breakpoint, etc.)\r\n",
      "      - id: detect-private-key       # checks for private keys (BEGIN X PRIVATE KEY, etc.)\r\n"
     ]
    }
   ],
   "source": [
    "!cat .pre-commit-config.yaml | grep repos -A 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eddb7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  # flake8 python linter with all the fixins\r\n",
      "  - repo: https://github.com/PyCQA/flake8\r\n",
      "    rev: 3.9.2\r\n",
      "    hooks:\r\n",
      "      - id: flake8\r\n",
      "        exclude: (lab01|lab02|lab03|lab04|lab06|lab07|lab08)\r\n",
      "        additional_dependencies: [\r\n",
      "          flake8-annotations, flake8-bandit, flake8-bugbear, flake8-black, flake8-docstrings,\r\n",
      "          flake8-import-order, darglint, mypy, pycodestyle, pydocstyle]\r\n",
      "        args: [\"--config\", \".flake8\"]\r\n",
      "    # additional configuration of flake8 and extensions in .flake8\r\n"
     ]
    }
   ],
   "source": [
    "!cat .pre-commit-config.yaml | grep \"flake8 python\" -A 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "868e7758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flake8]\r\n",
      "select = ANN,B,B9,BLK,C,D,E,F,I,S,W\r\n",
      "  # only check selected error codes\r\n",
      "max-complexity = 12\r\n",
      "  # C9 - flake8 McCabe Complexity checker -- threshold\r\n",
      "max-line-length = 120\r\n",
      "  # E501 - flake8 -- line length too long, actually handled by black\r\n",
      "extend-ignore =\r\n",
      "  # E W - flake8 PEP style check\r\n",
      "    E203,E402,E501,W503,  # whitespace, import, line length, binary operator line breaks\r\n",
      "  # S - flake8-bandit safety check\r\n",
      "    S101,S311,S105,  # assert removed in bytecode, pRNG not secure, hardcoded password\r\n",
      "  # ANN - flake8-annotations type annotation check\r\n",
      "    ANN,ANN002,ANN003,ANN101,ANN102,ANN202,  # ignore all for now, but always ignore some\r\n",
      "  # D1 - flake8-docstrings docstring style check\r\n",
      "    D100,D102,D103,D104,D105,  # missing docstrings\r\n",
      "  # D2 D4 - flake8-docstrings docstring style check\r\n",
      "    D200,D205,D400,D401,  # whitespace issues and first line content\r\n",
      "  # DAR - flake8-darglint docstring correctness check\r\n",
      "    DAR103,  # mismatched or missing type in docstring\r\n",
      "application-import-names = app_gradio,text_recognizer,tests,training\r\n",
      "  # flake8-import-order: which names are first party?\r\n",
      "import-order-style = google\r\n",
      "  # flake8-import-order: which import order style guide do we use?\r\n",
      "docstring-convention = numpy\r\n",
      "  # flake8-docstrings: which docstring style guide do we use?\r\n",
      "strictness = short\r\n",
      "  # darglint: how \"strict\" are we with docstring completeness?\r\n",
      "docstring-style = numpy\r\n",
      "  # darglint: which docstring style guide do we use?\r\n",
      "suppress-none-returning = true\r\n",
      "  # flake8-annotations: do we allow un-annotated Nones in returns?\r\n",
      "mypy-init-return = true\r\n",
      "  # flake8-annotations: do we allow init to have no return annotation?\r\n",
      "per-file-ignores =\r\n",
      "  # list of case-by-case ignores, see files for details\r\n",
      "  */__init__.py:F401,I\r\n",
      "  */data/*.py:DAR\r\n",
      "  *text_recognizer/util.py:DAR101,F401\r\n",
      "  *training/run_experiment.py:I202\r\n",
      "  *app_gradio/app.py:I202\r\n"
     ]
    }
   ],
   "source": [
    "!cat .flake8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1c1d0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "set -uo pipefail\r\n",
      "set +e\r\n",
      "\r\n",
      "FAILURE=false\r\n",
      "\r\n",
      "# apply automatic formatting\r\n",
      "echo \"black\"\r\n",
      "pre-commit run black || FAILURE=true\r\n",
      "\r\n",
      "# check for python code style violations, see .flake8 for details\r\n",
      "echo \"flake8\"\r\n",
      "pre-commit run flake8 || FAILURE=true\r\n",
      "\r\n",
      "# check for shell scripting style violations and common bugs\r\n",
      "echo \"shellcheck\"\r\n",
      "pre-commit run shellcheck || FAILURE=true\r\n",
      "\r\n",
      "# check python types\r\n",
      "echo \"mypy\"\r\n",
      "pre-commit run mypy || FAILURE=true\r\n",
      "\r\n",
      "if [ \"$FAILURE\" = true ]; then\r\n",
      "  echo \"Linting failed\"\r\n",
      "  exit 1\r\n",
      "fi\r\n",
      "echo \"Linting passed\"\r\n",
      "exit 0\r\n"
     ]
    }
   ],
   "source": [
    "!cat tasks/lint.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41413f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "set -uo pipefail\r\n",
      "set +e\r\n",
      "\r\n",
      "FAILURE=false\r\n",
      "\r\n",
      "# apply automatic formatting\r\n",
      "echo \"black\"\r\n",
      "pre-commit run black || FAILURE=true\r\n",
      "\r\n",
      "# check for python code style violations, see .flake8 for details\r\n",
      "echo \"flake8\"\r\n",
      "pre-commit run flake8 || FAILURE=true\r\n",
      "\r\n",
      "# check for shell scripting style violations and common bugs\r\n",
      "echo \"shellcheck\"\r\n",
      "pre-commit run shellcheck || FAILURE=true\r\n",
      "\r\n",
      "# check python types\r\n",
      "echo \"mypy\"\r\n",
      "pre-commit run mypy || FAILURE=true\r\n",
      "\r\n",
      "if [ \"$FAILURE\" = true ]; then\r\n",
      "  echo \"Linting failed\"\r\n",
      "  exit 1\r\n",
      "fi\r\n",
      "echo \"Linting passed\"\r\n",
      "exit 0\r\n"
     ]
    }
   ],
   "source": [
    "!cat tasks/lint.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dad96b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shellcheck...............................................................\u001b[42mPassed\u001b[m\n"
     ]
    }
   ],
   "source": [
    "script_filename = \"tasks/lint.sh\"\n",
    "!pre-commit run shellcheck --files {script_filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efab090c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "set -uo pipefail\r\n",
      "set +e\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 3 tasks/lint.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1db70e",
   "metadata": {},
   "source": [
    "### Testing ML Codebases\n",
    "\n",
    "**PyTest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ff3fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.lit_models.metrics import test_character_error_rate\n",
    "\n",
    "test_character_error_rate??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a18bf55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.7.13, pytest-7.1.1, pluggy-1.0.0\n",
      "rootdir: /home/jobquiroz/full_stack_deep_learning/lab05\n",
      "plugins: typeguard-2.13.3, anyio-3.6.1, cov-3.0.0\n",
      "collected 1 item                                                               \u001b[0m\u001b[1m\n",
      "\n",
      "text_recognizer/lit_models/metrics.py \u001b[32m.\u001b[0m\u001b[32m                                  [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 1.75s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest text_recognizer/lit_models/metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83bbc366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_callback_utils.py\ttest_iam.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls text_recognizer/tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65941b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tests for the text_recognizer.callbacks.util module.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from text_recognizer.tests import test_callback_utils\n",
    "\n",
    "test_callback_utils.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35f8ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.callbacks.util import check_and_warn\n",
    "\n",
    "check_and_warn??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb0203a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_callback_utils.test_check_and_warn_simple??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8eceeb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.lit_models.util import first_appearance\n",
    "\n",
    "\n",
    "first_appearance??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f5f5832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 3, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "first_appearance(torch.tensor([[1, 2, 3], [2, 3, 3], [1, 1, 1], [3, 1, 1]]), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50e4edf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.7.13, pytest-7.1.1, pluggy-1.0.0\n",
      "rootdir: /home/jobquiroz/full_stack_deep_learning/lab05\n",
      "plugins: typeguard-2.13.3, anyio-3.6.1, cov-3.0.0\n",
      "collected 2 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "text_recognizer/lit_models/util.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                    [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 1.74s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest --doctest-modules text_recognizer/lit_models/util.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d01c2666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_recognizer/data/iam_paragraphs.py:        self.input_dims = metadata.DIMS  # We assert that this is correct in setup()\r\n",
      "text_recognizer/data/iam_paragraphs.py:        self.output_dims = metadata.OUTPUT_DIMS  # We assert that this is correct in setup()\r\n",
      "text_recognizer/data/iam_paragraphs.py:    assert input_dims is not None and input_dims[1] >= max_image_shape[0] and input_dims[2] >= max_image_shape[1]\r\n",
      "text_recognizer/data/iam_paragraphs.py:    assert output_dims is not None and output_dims[0] >= properties[\"label_length\"][\"max\"] + 2\r\n",
      "text_recognizer/data/iam_paragraphs.py:    assert len(crops) == len(labels)\r\n",
      "text_recognizer/data/iam_paragraphs.py:    assert len(ordered_crops) == len(ordered_labels)\r\n",
      "text_recognizer/data/iam.py:    assert any(region is not None for region in line_regions), \"Line regions cannot be None\"\r\n",
      "text_recognizer/data/iam_lines.py:        self.input_dims = metadata.DIMS  # We assert that this is correct in setup()\r\n",
      "text_recognizer/data/iam_lines.py:        self.output_dims = metadata.OUTPUT_DIMS  # We assert that this is correct in setup()\r\n",
      "text_recognizer/data/iam_lines.py:            assert image_width <= metadata.IMAGE_WIDTH\r\n",
      "text_recognizer/data/iam_lines.py:            assert self.output_dims[0] >= max([len(_) for _ in labels_train]) + 2  # Add 2 for start/end tokens.\r\n",
      "text_recognizer/data/iam_lines.py:            assert self.output_dims[0] >= max([len(_) for _ in labels_val]) + 2  # Add 2 for start/end tokens.\r\n",
      "text_recognizer/data/iam_lines.py:            assert self.output_dims[0] >= max([len(_) for _ in labels_test]) + 2\r\n",
      "text_recognizer/data/iam_lines.py:    assert len(crops) == len(labels)\r\n",
      "text_recognizer/data/iam_lines.py:    assert len(crops) == len(labels)\r\n"
     ]
    }
   ],
   "source": [
    "!grep \"assert\" -r text_recognizer/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2043dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.tests.test_iam import test_iam_data_splits\n",
    "\n",
    "test_iam_data_splits??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eba8aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iam_data_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b6ce90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@pytest.mark.no_cover: disable coverage for this test.\r\n",
      "\r\n",
      "@pytest.mark.anyio: mark the (coroutine function) test to be run asynchronously via anyio.\r\n",
      "\r\n",
      "@pytest.mark.filterwarnings(warning): add a warning filter to the given test. see https://docs.pytest.org/en/stable/how-to/capture-warnings.html#pytest-mark-filterwarnings \r\n",
      "\r\n",
      "@pytest.mark.skip(reason=None): skip the given test function with an optional reason. Example: skip(reason=\"no way of currently testing this\") skips the test.\r\n",
      "\r\n",
      "@pytest.mark.skipif(condition, ..., *, reason=...): skip the given test function if any of the conditions evaluate to True. Example: skipif(sys.platform == 'win32') skips the test if we are on the win32 platform. See https://docs.pytest.org/en/stable/reference/reference.html#pytest-mark-skipif\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!pytest --markers | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74dfcce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjobquiroz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.7.13, pytest-7.1.1, pluggy-1.0.0\n",
      "rootdir: /home/jobquiroz/full_stack_deep_learning/lab05\n",
      "plugins: typeguard-2.13.3, anyio-3.6.1, cov-3.0.0\n",
      "collected 5 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "text_recognizer/tests/test_callback_utils.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                         [ 60%]\u001b[0m\n",
      "text_recognizer/tests/test_iam.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                     [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m5 passed\u001b[0m\u001b[32m in 9.83s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!wandb login  # one test requires wandb authentication\n",
    "\n",
    "!pytest -m \"not data and not slow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec632996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebooks  tasks  text_recognizer  training  wandb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74dad6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fake images dataset.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from text_recognizer.data import FakeImageData\n",
    "\n",
    "\n",
    "FakeImageData.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a87cdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "set -uo pipefail\r\n",
      "set +e\r\n",
      "\r\n",
      "FAILURE=false\r\n",
      "\r\n",
      "echo \"running full loop test with CNN on fake data\"\r\n",
      "python training/run_experiment.py --data_class=FakeImageData --model_class=CNN --conv_dim=2 --fc_dim=2 --loss=cross_entropy --num_workers=4 --max_epochs=1 || FAILURE=true\r\n",
      "\r\n",
      "echo \"running fast_dev_run test of real model class on real data\"\r\n",
      "python training/run_experiment.py --data_class=IAMParagraphs --model_class=ResnetTransformer --loss=transformer \\\r\n",
      "  --tf_dim 4 --tf_fc_dim 2 --tf_layers 2 --tf_nhead 2 --batch_size 2 --lr 0.0001 \\\r\n",
      "  --fast_dev_run --num_sanity_val_steps 0 \\\r\n",
      "  --num_workers 1 || FAILURE=true\r\n",
      "\r\n",
      "if [ \"$FAILURE\" = true ]; then\r\n",
      "  echo \"Test for run_experiment.py failed\"\r\n",
      "  exit 1\r\n",
      "fi\r\n",
      "echo \"Tests for run_experiment.py passed\"\r\n",
      "exit 0\r\n"
     ]
    }
   ],
   "source": [
    "!cat training/tests/test_run_experiment.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a3e34fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running full loop test with CNN on fake data\n",
      "Missing logger folder: training/logs/lightning_logs\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/jobquiroz/miniconda3/envs/fsdl-text-recognizer-2022/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1815: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  category=PossibleUserWarning,\n",
      "\n",
      "  | Name           | Type      | Params\n",
      "---------------------------------------------\n",
      "0 | model          | CNN       | 874   \n",
      "1 | model.conv1    | ConvBlock | 20    \n",
      "2 | model.conv2    | ConvBlock | 38    \n",
      "3 | model.dropout  | Dropout   | 0     \n",
      "4 | model.max_pool | MaxPool2d | 0     \n",
      "5 | model.fc1      | Linear    | 786   \n",
      "6 | model.fc2      | Linear    | 30    \n",
      "7 | train_acc      | Accuracy  | 0     \n",
      "8 | val_acc        | Accuracy  | 0     \n",
      "9 | test_acc       | Accuracy  | 0     \n",
      "---------------------------------------------\n",
      "874       Trainable params\n",
      "0         Non-trainable params\n",
      "874       Total params\n",
      "0.003     Total estimated model params size (MB)\n",
      "Model State Dict Disk Size: 0.01 MB\n",
      "/home/jobquiroz/miniconda3/envs/fsdl-text-recognizer-2022/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1931: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  category=PossibleUserWarning,\n",
      "Epoch 0:  67%|██████████▋     | 2/3 [00:00<00:00, 15.05it/s, loss=2.36, v_num=0]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 3/3 [00:00<00:00, 13.19it/s, loss=2.36, v_num=0, validation/los\u001b[A\n",
      "Epoch 0: 100%|█| 3/3 [00:00<00:00, 12.63it/s, loss=2.36, v_num=0, validation/los\u001b[A\n",
      "Testing DataLoader 0: 100%|███████████████████████| 1/1 [00:00<00:00, 39.41it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "        test/acc                 0.078125\n",
      "        test/loss            2.394085645675659\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Best model saved at: /home/jobquiroz/full_stack_deep_learning/lab05/training/logs/lightning_logs/version_0/epoch=0000-validation.loss=2.373.ckpt\n",
      "running fast_dev_run test of real model class on real data\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/jobquiroz/miniconda3/envs/fsdl-text-recognizer-2022/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1815: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  category=PossibleUserWarning,\n",
      "Running in fast_dev_run mode: will run a full train, val, test and prediction loop using 1 batch(es).\n",
      "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(limit_predict_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "IAMParagraphs.prepare_data: Cropping IAM paragraph regions and saving them along with labels...\n",
      "IAMParagraphs.setup(fit): Loading IAM paragraph regions and lines...\n",
      "\n",
      "   | Name                      | Type                    | Params\n",
      "-----------------------------------------------------------------------\n",
      "0  | model                     | ResnetTransformer       | 11.2 M\n",
      "1  | model.resnet              | Sequential              | 11.2 M\n",
      "2  | model.encoder_projection  | Conv2d                  | 2.1 K \n",
      "3  | model.enc_pos_encoder     | PositionalEncodingImage | 0     \n",
      "4  | model.embedding           | Embedding               | 336   \n",
      "5  | model.fc                  | Linear                  | 420   \n",
      "6  | model.dec_pos_encoder     | PositionalEncoding      | 0     \n",
      "7  | model.transformer_decoder | TransformerDecoder      | 412   \n",
      "8  | train_acc                 | Accuracy                | 0     \n",
      "9  | val_acc                   | Accuracy                | 0     \n",
      "10 | test_acc                  | Accuracy                | 0     \n",
      "11 | val_cer                   | CharacterErrorRate      | 0     \n",
      "12 | test_cer                  | CharacterErrorRate      | 0     \n",
      "13 | loss_fn                   | CrossEntropyLoss        | 0     \n",
      "-----------------------------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.719    Total estimated model params size (MB)\n",
      "Model State Dict Disk Size: 44.81 MB\n",
      "/home/jobquiroz/miniconda3/envs/fsdl-text-recognizer-2022/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "/home/jobquiroz/miniconda3/envs/fsdl-text-recognizer-2022/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1931: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  category=PossibleUserWarning,\n",
      "/home/jobquiroz/miniconda3/envs/fsdl-text-recognizer-2022/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "Epoch 0:  50%|████████▌        | 1/2 [00:01<00:01,  1.91s/it, loss=4.44, v_num=]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 1/1 [00:01<00:00,  1.20s/it]\u001b[A\n",
      "Epoch 0: 100%|█| 2/2 [00:03<00:00,  1.60s/it, loss=4.44, v_num=, validation/loss\u001b[A\n",
      "Epoch 0: 100%|█| 2/2 [00:03<00:00,  1.60s/it, loss=4.44, v_num=, validation/loss\u001b[A\n",
      "IAMParagraphs.setup(test): Loading IAM paragraph regions and lines...\n",
      "/home/jobquiroz/miniconda3/envs/fsdl-text-recognizer-2022/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "Testing DataLoader 0: 100%|███████████████████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "        test/cer            0.9877883195877075\n",
      "        test/loss            4.444047927856445\n",
      "────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests for run_experiment.py passed\r\n"
     ]
    }
   ],
   "source": [
    "! ./training/tests/test_run_experiment.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "593e7d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "set -uo pipefail\r\n",
      "set +e\r\n",
      "\r\n",
      "# tests whether we can achieve a criterion loss\r\n",
      "#  on a single batch within a certain number of epochs\r\n",
      "\r\n",
      "FAILURE=false\r\n",
      "\r\n",
      "# constants and CLI args set by aiming for <5 min test on commodity GPU,\r\n",
      "#   including data download step\r\n",
      "MAX_EPOCHS=\"${1:-100}\"  # syntax for basic optional arguments in bash\r\n",
      "CRITERION=\"${2:-1.0}\"\r\n",
      "\r\n",
      "# train on GPU if it's available\r\n",
      "GPU=$(python -c 'import torch; print(int(torch.cuda.is_available()))')\r\n",
      "\r\n",
      "python ./training/run_experiment.py \\\r\n",
      "  --data_class=IAMParagraphs --model_class=ResnetTransformer --loss=transformer \\\r\n",
      "  --limit_test_batches 0.0 --overfit_batches 1 --num_sanity_val_steps 0 \\\r\n",
      "  --augment_data false --tf_dropout 0.0 \\\r\n",
      "  --gpus \"$GPU\" --precision 16 --batch_size 16 --lr 0.0001 \\\r\n",
      "  --log_every_n_steps 25 --max_epochs \"$MAX_EPOCHS\"  --num_workers 2 --wandb || FAILURE=true\r\n",
      "\r\n",
      "python -c \"import json; loss = json.load(open('training/logs/wandb/latest-run/files/wandb-summary.json'))['train/loss']; assert loss < $CRITERION\" || FAILURE=true\r\n",
      "\r\n",
      "if [ \"$FAILURE\" = true ]; then\r\n",
      "  echo \"Memorization test failed at loss criterion $CRITERION\"\r\n",
      "  exit 1\r\n",
      "fi\r\n",
      "echo \"Memorization test passed at loss criterion $CRITERION\"\r\n",
      "exit 0\r\n"
     ]
    }
   ],
   "source": [
    "!cat training/tests/test_memorize_iam.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6954dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(int(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60217773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjobquiroz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mtraining/logs/wandb/run-20220831_195214-2v3kp9yq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdauntless-frog-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jobquiroz/full_stack_deep_learning-lab05_training\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/jobquiroz/full_stack_deep_learning-lab05_training/runs/2v3kp9yq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n",
      "IAMParagraphs.setup(fit): Loading IAM paragraph regions and lines...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                      | Type                    | Params\n",
      "-----------------------------------------------------------------------\n",
      "0  | model                     | ResnetTransformer       | 14.0 M\n",
      "1  | model.resnet              | Sequential              | 11.2 M\n",
      "2  | model.encoder_projection  | Conv2d                  | 131 K \n",
      "3  | model.enc_pos_encoder     | PositionalEncodingImage | 0     \n",
      "4  | model.embedding           | Embedding               | 21.5 K\n",
      "5  | model.fc                  | Linear                  | 21.6 K\n",
      "6  | model.dec_pos_encoder     | PositionalEncoding      | 0     \n",
      "7  | model.transformer_decoder | TransformerDecoder      | 2.6 M \n",
      "8  | train_acc                 | Accuracy                | 0     \n",
      "9  | val_acc                   | Accuracy                | 0     \n",
      "10 | test_acc                  | Accuracy                | 0     \n",
      "11 | val_cer                   | CharacterErrorRate      | 0     \n",
      "12 | test_cer                  | CharacterErrorRate      | 0     \n",
      "13 | loss_fn                   | CrossEntropyLoss        | 0     \n",
      "-----------------------------------------------------------------------\n",
      "14.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "14.0 M    Total params\n",
      "27.978    Total estimated model params size (MB)\n",
      "Model State Dict Disk Size: 56.06 MB\n",
      "/home/jobquiroz/miniconda3/envs/fsdl-text-recognizer-2022/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:472: UserWarning: You requested to overfit but enabled training dataloader shuffling. We are turning off the training dataloader shuffling for you.\n",
      "  \"You requested to overfit but enabled training dataloader shuffling.\"\n",
      "/home/jobquiroz/miniconda3/envs/fsdl-text-recognizer-2022/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "/home/jobquiroz/miniconda3/envs/fsdl-text-recognizer-2022/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1931: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=25). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  category=PossibleUserWarning,\n",
      "Epoch 0: 100%|█████████████| 1/1 [00:02<00:00,  2.82s/it, loss=4.34, v_num=p9yq]/home/jobquiroz/miniconda3/envs/fsdl-text-recognizer-2022/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:378: UserWarning: `ModelCheckpoint(monitor='validation/cer')` could not find the monitored key in the returned metrics: ['train/loss', 'epoch', 'step']. HINT: Did you call `log('validation/cer', value)` in the `LightningModule`?\n",
      "  warning_cache.warn(m)\n",
      "Epoch 999: 100%|█████████| 1/1 [00:03<00:00,  3.04s/it, loss=0.0175, v_num=p9yq]\n",
      "IAMParagraphs.setup(test): Loading IAM paragraph regions and lines...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B sync reduced upload amount by 63.6%             \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   optimizer/lr-Adam ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        size/mb_disk ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        size/nparams ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/loss █▆▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: trainer/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   optimizer/lr-Adam 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        size/mb_disk 56.06463\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        size/nparams 13988756\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/loss 0.01387\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: trainer/global_step 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdauntless-frog-1\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/jobquiroz/full_stack_deep_learning-lab05_training/runs/2v3kp9yq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 41 media file(s), 56 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mtraining/logs/wandb/run-20220831_195214-2v3kp9yq/logs\u001b[0m\n",
      "Memorization test passed at loss criterion 0.05\n",
      "CPU times: user 10.7 s, sys: 2.84 s, total: 13.5 s\n",
      "Wall time: 9min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "running_memorization = True\n",
    "\n",
    "if running_memorization:\n",
    "    max_epochs = 1000\n",
    "    loss_criterion = 0.05\n",
    "    !./training/tests/test_memorize_iam.sh {max_epochs} {loss_criterion}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80ea9713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --profile             If passed, uses the PyTorch Profiler to track\r\n",
      "                        computation, exported as a Chrome-style trace.\r\n"
     ]
    }
   ],
   "source": [
    "!python training/run_experiment.py --help | grep -A 1 -e \"^\\s*--profile\\s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2130f34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    if args.profile:\r\n",
      "        sched = torch.profiler.schedule(wait=0, warmup=3, active=4, repeat=0)\r\n",
      "        profiler = pl.profiler.PyTorchProfiler(export_to_chrome=True, schedule=sched, dirpath=experiment_dir)\r\n",
      "        profiler.STEP_FUNCTIONS = {\"training_step\"}  # only profile training\r\n",
      "    else:\r\n",
      "        profiler = pl.profiler.PassThroughProfiler()\r\n"
     ]
    }
   ],
   "source": [
    "!cat training/run_experiment.py | grep args.profile -A 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f390f31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_JOB_TYPE=profile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjobquiroz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>training/logs/wandb/run-20220831_202045-3ri7hbh6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jobquiroz/full_stack_deep_learning-lab05_training/runs/3ri7hbh6\" target=\"_blank\">easy-microwave-2</a></strong> to <a href=\"https://wandb.ai/jobquiroz/full_stack_deep_learning-lab05_training\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "IAMParagraphs.setup(fit): Loading IAM paragraph regions and lines...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                      | Type                    | Params\n",
      "-----------------------------------------------------------------------\n",
      "0  | model                     | ResnetTransformer       | 14.0 M\n",
      "1  | model.resnet              | Sequential              | 11.2 M\n",
      "2  | model.encoder_projection  | Conv2d                  | 131 K \n",
      "3  | model.enc_pos_encoder     | PositionalEncodingImage | 0     \n",
      "4  | model.embedding           | Embedding               | 21.5 K\n",
      "5  | model.fc                  | Linear                  | 21.6 K\n",
      "6  | model.dec_pos_encoder     | PositionalEncoding      | 0     \n",
      "7  | model.transformer_decoder | TransformerDecoder      | 2.6 M \n",
      "8  | train_acc                 | Accuracy                | 0     \n",
      "9  | val_acc                   | Accuracy                | 0     \n",
      "10 | test_acc                  | Accuracy                | 0     \n",
      "11 | val_cer                   | CharacterErrorRate      | 0     \n",
      "12 | test_cer                  | CharacterErrorRate      | 0     \n",
      "13 | loss_fn                   | CrossEntropyLoss        | 0     \n",
      "-----------------------------------------------------------------------\n",
      "14.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "14.0 M    Total params\n",
      "27.978    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model State Dict Disk Size: 56.06 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfcdd4c0da624bdbab232e8731e0011a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jobquiroz/miniconda3/envs/fsdl-text-recognizer-2022/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:378: UserWarning: `ModelCheckpoint(monitor='validation/cer')` could not find the monitored key in the returned metrics: ['train/loss', 'epoch', 'step']. HINT: Did you call `log('validation/cer', value)` in the `LightningModule`?\n",
      "  warning_cache.warn(m)\n",
      "FIT Profiler Report\n",
      "Profile stats for: records\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*        10.52%     291.233ms        48.38%        1.339s     334.731ms       0.000us         0.00%     126.620ms      31.655ms             4  \n",
      "                        [pl][profile]run_training_batch         0.12%       3.191ms        35.47%     981.718ms     327.239ms       0.000us         0.00%     289.667ms      96.556ms             3  \n",
      "[pl][profile][LightningModule]TransformerLitModel.op...        25.80%     714.036ms        35.35%     978.507ms     326.169ms       0.000us         0.00%     289.667ms      96.556ms             3  \n",
      "[pl][profile][Strategy]SingleDeviceStrategy.backward...        16.22%     448.973ms        16.30%     451.232ms     112.808ms       0.000us         0.00%       8.000us       2.000us             4  \n",
      "[pl][profile][Strategy]SingleDeviceStrategy.training...         0.60%      16.509ms        11.88%     328.897ms      82.224ms       0.000us         0.00%     387.512ms      96.878ms             4  \n",
      "                                             aten::item         0.33%       9.017ms        11.14%     308.441ms     554.750us       0.000us         0.00%       7.000us       0.013us           556  \n",
      "                                        cudaMemcpyAsync        10.93%     302.636ms        10.93%     302.636ms       4.729ms       0.000us         0.00%       0.000us       0.000us            64  \n",
      "                              aten::_local_scalar_dense         0.02%     529.000us        10.82%     299.424ms     538.532us       7.000us         0.00%       7.000us       0.013us           556  \n",
      "                                  cudaStreamSynchronize         9.69%     268.203ms         9.69%     268.203ms      13.410ms       0.000us         0.00%       0.000us       0.000us            20  \n",
      "                                            aten::copy_         1.05%      29.083ms         7.66%     211.905ms     118.251us     111.951ms        10.02%     112.574ms      62.820us          1792  \n",
      "autograd::engine::evaluate_function: EmbeddingBackwa...         0.00%     102.000us         7.25%     200.704ms      50.176ms       0.000us         0.00%       1.723ms     430.750us             4  \n",
      "                                     EmbeddingBackward0         0.02%     442.000us         7.25%     200.602ms      50.151ms       0.000us         0.00%       1.723ms     430.750us             4  \n",
      "                               aten::embedding_backward         0.00%      19.000us         7.23%     200.160ms      50.040ms       0.000us         0.00%       1.723ms     430.750us             4  \n",
      "                         aten::embedding_dense_backward         0.05%       1.268ms         7.23%     200.141ms      50.035ms       1.704ms         0.15%       1.723ms     430.750us             4  \n",
      "                               Optimizer.step#Adam.step         1.66%      46.020ms         6.66%     184.314ms      46.078ms       0.000us         0.00%      17.884ms       4.471ms             4  \n",
      "                                       cudaLaunchKernel         5.37%     148.684ms         5.37%     148.684ms      14.520us       0.000us         0.00%       0.000us       0.000us         10240  \n",
      "                                               aten::to         0.09%       2.477ms         5.20%     143.852ms      93.898us       0.000us         0.00%      76.637ms      50.024us          1532  \n",
      "                                         aten::_to_copy         0.73%      20.227ms         5.11%     141.375ms      94.250us       0.000us         0.00%      76.637ms      51.091us          1500  \n",
      "[pl][module]torch.nn.modules.transformer.Transformer...         0.02%     666.000us         4.55%     125.904ms      31.476ms       0.000us         0.00%     215.033ms      53.758ms             4  \n",
      "                                          aten::type_as         0.00%      18.000us         3.14%      86.891ms      21.723ms       0.000us         0.00%     623.000us     155.750us             4  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.768s\n",
      "Self CUDA time total: 1.118s\n",
      "\n",
      "IAMParagraphs.setup(test): Loading IAM paragraph regions and lines...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='24.023 MB of 24.023 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>optimizer/lr-Adam</td><td>▁▁</td></tr><tr><td>size/mb_disk</td><td>▁</td></tr><tr><td>size/nparams</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁▁███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>optimizer/lr-Adam</td><td>0.001</td></tr><tr><td>size/mb_disk</td><td>56.06463</td></tr><tr><td>size/nparams</td><td>13988756</td></tr><tr><td>train/loss</td><td>3.17177</td></tr><tr><td>trainer/global_step</td><td>49</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">easy-microwave-2</strong>: <a href=\"https://wandb.ai/jobquiroz/full_stack_deep_learning-lab05_training/runs/3ri7hbh6\" target=\"_blank\">https://wandb.ai/jobquiroz/full_stack_deep_learning-lab05_training/runs/3ri7hbh6</a><br/>Synced 6 W&B file(s), 2 media file(s), 18 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>training/logs/wandb/run-20220831_202045-3ri7hbh6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from text_recognizer.data.base_data_module import DEFAULT_NUM_WORKERS\n",
    "\n",
    "\n",
    "# make it easier to separate these from training runs\n",
    "%env WANDB_JOB_TYPE=profile\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = DEFAULT_NUM_WORKERS  # change this number later and see how the results change\n",
    "gpus = 1  # must be run with accelerator\n",
    "\n",
    "%run training/run_experiment.py --wandb --profile \\\n",
    "  --max_epochs=1 \\\n",
    "  --num_sanity_val_steps=0 --limit_val_batches=0 --limit_test_batches=0 \\\n",
    "  --model_class=ResnetTransformer --data_class=IAMParagraphs --loss=transformer \\\n",
    "  --batch_size={batch_size} --num_workers={num_workers} --precision=16 --gpus=1\n",
    "\n",
    "latest_expt = wandb.run\n",
    "\n",
    "try:  # add execution trace to logged and versioned binaries\n",
    "    folder = wandb.run.dir\n",
    "    trace_matcher = wandb.run.dir + \"/*.pt.trace.json\"\n",
    "    trace_file = glob.glob(trace_matcher)[0]\n",
    "    trace_at = wandb.Artifact(name=f\"trace-{wandb.run.id}\", type=\"trace\")\n",
    "    trace_at.add_file(trace_file, name=\"training_step.pt.trace.json\")\n",
    "    wandb.log_artifact(trace_at)\n",
    "except IndexError:\n",
    "    print(\"trace not found\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ece66182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://wandb.ai/jobquiroz/full_stack_deep_learning-lab05_training/runs/3ri7hbh6/tensorboard\n"
     ]
    }
   ],
   "source": [
    "your_tensorboard_url = latest_expt.url + \"/tensorboard\"\n",
    "\n",
    "print(your_tensorboard_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58f23093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://wandb.ai/jobquiroz/full_stack_deep_learning-lab05_training/artifacts/trace/trace-3ri7hbh6/latest/files/training_step.pt.trace.json\n"
     ]
    }
   ],
   "source": [
    "trace_files_url = latest_expt.url.split(\"/runs/\")[0] + f\"/artifacts/trace/trace-{latest_expt.id}/latest/files/\"\n",
    "trace_url = trace_files_url + \"training_step.pt.trace.json\"\n",
    "\n",
    "example_trace_url = \"https://wandb.ai/cfrye59/fsdl-text-recognizer-2022-training/artifacts/trace/trace-67j1qxws/latest/files/training_step.pt.trace.json\"\n",
    "\n",
    "print(trace_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c6282f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
